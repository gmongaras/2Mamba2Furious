{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19bb72db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ad91545",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int):\n",
    "    import random, os\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    \n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2167f1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 1\n",
    "N = 128\n",
    "H = 1\n",
    "d = 64\n",
    "query_states = torch.randn(B, H, N, d, device=torch.device(\"cuda:0\"), dtype=torch.bfloat16).requires_grad_()\n",
    "key_states = torch.randn_like(query_states).requires_grad_()\n",
    "value_states = torch.randn_like(query_states).requires_grad_()\n",
    "A = (-torch.nn.functional.softplus(torch.randn(B, N, H, device=torch.device(\"cuda:0\"), dtype=torch.bfloat16))).requires_grad_()\n",
    "\n",
    "query_states_ = query_states.detach().clone().requires_grad_()\n",
    "key_states_ = key_states.detach().clone().requires_grad_()\n",
    "value_states_ = value_states.detach().clone().requires_grad_()\n",
    "A_ = A.detach().clone().requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6410ff8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b74e5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06ebb5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/gmongaras/miniconda3/lib/python3.10/site-packages/torch/autograd/gradcheck.py:922: UserWarning: Input #1 requires gradient and is not a double precision floating point or complex. This check will likely fail if all the inputs are not of double precision floating point or complex. \n",
      "  warnings.warn(\n",
      "/users/gmongaras/miniconda3/lib/python3.10/site-packages/torch/autograd/gradcheck.py:922: UserWarning: Input #3 requires gradient and is not a double precision floating point or complex. This check will likely fail if all the inputs are not of double precision floating point or complex. \n",
      "  warnings.warn(\n",
      "/users/gmongaras/miniconda3/lib/python3.10/site-packages/torch/autograd/gradcheck.py:922: UserWarning: Input #4 requires gradient and is not a double precision floating point or complex. This check will likely fail if all the inputs are not of double precision floating point or complex. \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "GradcheckError",
     "evalue": "Jacobian mismatch for output 0 with respect to input 0,\nnumerical:tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n        ...,\n        [ 0.0000,  0.0000,  0.0000,  ..., -0.0978, -0.0763, -0.0358],\n        [ 0.0000,  0.0000,  0.0000,  ..., -0.0978, -0.0763, -0.0358],\n        [ 0.0000,  0.0000,  0.0000,  ..., -0.0978, -0.0763, -0.0358]],\n       device='cuda:0')\nanalytical:tensor([[ 0.7588,  0.7588,  0.7588,  ...,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n        ...,\n        [ 0.0000,  0.0000,  0.0000,  ..., -0.0360, -0.0463, -0.0268],\n        [ 0.0000,  0.0000,  0.0000,  ..., -0.4701, -0.4803, -0.4608],\n        [ 0.0000,  0.0000,  0.0000,  ..., -0.8468, -1.7886, -1.0932]],\n       device='cuda:0')\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mGradcheckError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m     query_states___ \u001b[38;5;241m=\u001b[39m query_states__\n\u001b[1;32m     16\u001b[0m     key_states__ \u001b[38;5;241m=\u001b[39m key_states_\n\u001b[0;32m---> 17\u001b[0m check \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmamba_chunk_scan_combined\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue_states__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequires_grad_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue_states__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_states__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_states__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_states___\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/autograd/gradcheck.py:2055\u001b[0m, in \u001b[0;36mgradcheck\u001b[0;34m(func, inputs, eps, atol, rtol, raise_exception, nondet_tol, check_undefined_grad, check_grad_dtypes, check_batched_grad, check_batched_forward_grad, check_forward_ad, check_backward_ad, fast_mode, masked)\u001b[0m\n\u001b[1;32m   2053\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   2054\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2055\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_gradcheck_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/autograd/gradcheck.py:2084\u001b[0m, in \u001b[0;36m_gradcheck_helper\u001b[0;34m(func, inputs, eps, atol, rtol, nondet_tol, check_undefined_grad, check_grad_dtypes, check_batched_grad, check_batched_forward_grad, check_forward_ad, check_backward_ad, fast_mode, masked)\u001b[0m\n\u001b[1;32m   2079\u001b[0m _check_outputs(outputs)\n\u001b[1;32m   2081\u001b[0m gradcheck_fn \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(\n\u001b[1;32m   2082\u001b[0m     _fast_gradcheck \u001b[38;5;28;01mif\u001b[39;00m fast_mode \u001b[38;5;28;01melse\u001b[39;00m _slow_gradcheck, masked\u001b[38;5;241m=\u001b[39mmasked\n\u001b[1;32m   2083\u001b[0m )\n\u001b[0;32m-> 2084\u001b[0m \u001b[43m_gradcheck_real_imag\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2085\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgradcheck_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2086\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2087\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc_out\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2088\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtupled_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2089\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2090\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2091\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2092\u001b[0m \u001b[43m    \u001b[49m\u001b[43matol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2093\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_grad_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2094\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_forward_ad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_forward_ad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2095\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_backward_ad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_backward_ad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2096\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnondet_tol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnondet_tol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_undefined_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_undefined_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2098\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_batched_forward_grad:\n\u001b[1;32m   2101\u001b[0m     _test_batched_grad_forward_ad(func, tupled_inputs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/autograd/gradcheck.py:1494\u001b[0m, in \u001b[0;36m_gradcheck_real_imag\u001b[0;34m(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps, rtol, atol, check_grad_dtypes, check_forward_ad, check_backward_ad, nondet_tol, check_undefined_grad)\u001b[0m\n\u001b[1;32m   1481\u001b[0m         gradcheck_fn(\n\u001b[1;32m   1482\u001b[0m             real_fn,\n\u001b[1;32m   1483\u001b[0m             real_func_out,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1491\u001b[0m             complex_indices\u001b[38;5;241m=\u001b[39mcomplex_out_indices,\n\u001b[1;32m   1492\u001b[0m         )\n\u001b[1;32m   1493\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1494\u001b[0m         \u001b[43mgradcheck_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1495\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1496\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc_out\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1497\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtupled_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1498\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1499\u001b[0m \u001b[43m            \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1500\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m            \u001b[49m\u001b[43matol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcheck_grad_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnondet_tol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_forward_ad:\n\u001b[1;32m   1507\u001b[0m     complex_inp_indices \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   1508\u001b[0m         i\n\u001b[1;32m   1509\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i, inp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tupled_inputs)\n\u001b[1;32m   1510\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m is_tensor_like(inp) \u001b[38;5;129;01mand\u001b[39;00m inp\u001b[38;5;241m.\u001b[39mis_complex()\n\u001b[1;32m   1511\u001b[0m     ]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/autograd/gradcheck.py:1635\u001b[0m, in \u001b[0;36m_slow_gradcheck\u001b[0;34m(func, func_out, tupled_inputs, outputs, eps, rtol, atol, check_grad_dtypes, nondet_tol, use_forward_ad, complex_indices, test_imag, masked)\u001b[0m\n\u001b[1;32m   1633\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m j, (a, n) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(analytical, numerical[i])):\n\u001b[1;32m   1634\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _allclose_with_type_promotion(a, n\u001b[38;5;241m.\u001b[39mto(a\u001b[38;5;241m.\u001b[39mdevice), rtol, atol):\n\u001b[0;32m-> 1635\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m GradcheckError(\n\u001b[1;32m   1636\u001b[0m                     _get_notallclose_msg(a, n, i, j, complex_indices, test_imag)\n\u001b[1;32m   1637\u001b[0m                 )\n\u001b[1;32m   1639\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mGradcheckError\u001b[0m: Jacobian mismatch for output 0 with respect to input 0,\nnumerical:tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n        ...,\n        [ 0.0000,  0.0000,  0.0000,  ..., -0.0978, -0.0763, -0.0358],\n        [ 0.0000,  0.0000,  0.0000,  ..., -0.0978, -0.0763, -0.0358],\n        [ 0.0000,  0.0000,  0.0000,  ..., -0.0978, -0.0763, -0.0358]],\n       device='cuda:0')\nanalytical:tensor([[ 0.7588,  0.7588,  0.7588,  ...,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n        ...,\n        [ 0.0000,  0.0000,  0.0000,  ..., -0.0360, -0.0463, -0.0268],\n        [ 0.0000,  0.0000,  0.0000,  ..., -0.4701, -0.4803, -0.4608],\n        [ 0.0000,  0.0000,  0.0000,  ..., -0.8468, -1.7886, -1.0932]],\n       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "order_ = 1\n",
    "def kron(X):\n",
    "    return (X[..., None] * X[..., None, :]).flatten(-2, -1)\n",
    "from Mamba_Custom import mamba_chunk_scan_combined\n",
    "chunk_size = 64\n",
    "# Note that mamba 2 still adds the *dt factor to the values. This needs to be removed in the kernel\n",
    "# It also doesn't have the factor_. To add this, you can just multiply the keys by the factor_\n",
    "query_states__ = query_states_ * 1/math.sqrt(key_states.shape[-1])\n",
    "value_states__ = value_states_ * 1/order_\n",
    "# To get the squared inner product, we need to explicitly do the kron prod\n",
    "if order_ == 2:\n",
    "    query_states___ = kron(query_states__)\n",
    "    key_states__ = kron(key_states_)\n",
    "else:\n",
    "    query_states___ = query_states__\n",
    "    key_states__ = key_states_\n",
    "check = torch.autograd.gradcheck(mamba_chunk_scan_combined, (value_states__.float().transpose(1, 2).detach().requires_grad_(False), A_.float(), torch.ones(value_states__.shape[1]).float().to(query_states__.device), key_states__.float().transpose(1, 2), query_states___.float().transpose(1, 2), chunk_size, None, None, None, None, None, None, False, (-float(\"inf\"), float(\"inf\")), False, False), eps=1e-4)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adb2334",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e06e53d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "903c2f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[False,  True,  True,  ...,  True,  True,  True],\n",
       "          [False, False,  True,  ...,  True,  True,  True],\n",
       "          [False, False, False,  ...,  True,  True,  True],\n",
       "          ...,\n",
       "          [False, False, False,  ..., False,  True,  True],\n",
       "          [False, False, False,  ..., False, False,  True],\n",
       "          [False, False, False,  ..., False, False, False]]]], device='cuda:0')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask = (torch.tril(torch.ones(N, N)) == 0)[None, None, ...].bool().cuda()\n",
    "attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8007cf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_ = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9169f1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accumulate over orders\n",
    "factor_ = 1/math.sqrt(key_states.shape[-1])\n",
    "\n",
    "# Convert to a value between 0 and 2\n",
    "order_coefficients = 1\n",
    "\n",
    "# if self.cumulative:\n",
    "weight_ = 1/order_\n",
    "_i = order_\n",
    "attn_weights = (weight_ * (query_states.float() @ key_states.float().mT * factor_)**_i)\n",
    "\n",
    "# Apply A mask\n",
    "A_cumsum = torch.cumsum(A.float(), dim=-2).mT\n",
    "A_mask = (((A_cumsum[:, :, :, None] - A_cumsum[:, :, None, :]))).masked_fill(attention_mask.bool(), -torch.inf).exp().to(query_states.dtype)\n",
    "attn_weights = attn_weights * A_mask\n",
    "\n",
    "out = attn_weights.bfloat16() @ value_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95335c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/gmongaras/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "def kron(X):\n",
    "    return (X[..., None] * X[..., None, :]).flatten(-2, -1)\n",
    "from Mamba_Custom import mamba_chunk_scan_combined\n",
    "chunk_size = 256\n",
    "# Note that mamba 2 still adds the *dt factor to the values. This needs to be removed in the kernel\n",
    "# It also doesn't have the factor_. To add this, you can just multiply the keys by the factor_\n",
    "query_states__ = query_states_ * 1/math.sqrt(key_states.shape[-1])\n",
    "value_states__ = value_states_ * 1/order_\n",
    "# To get the squared inner product, we need to explicitly do the kron prod\n",
    "if order_ == 2:\n",
    "    query_states___ = kron(query_states__)\n",
    "    key_states__ = kron(key_states_)\n",
    "else:\n",
    "    query_states___ = query_states__\n",
    "    key_states__ = key_states_\n",
    "out_ = mamba_chunk_scan_combined(x=value_states__.transpose(1, 2), dt=A_, A=torch.ones(value_states__.shape[1]).float().to(query_states__.device), B=key_states__.transpose(1, 2), C=query_states___.transpose(1, 2), chunk_size=chunk_size, D=None, z=None, dt_bias=None, initial_states=None, seq_idx=None, cu_seqlens=None, dt_softplus=False, dt_limit=(-float(\"inf\"), float(\"inf\")), return_final_states=False, return_varlen_states=False).transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b7d6488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1.1328e+00, -2.7188e+00,  5.2188e+00,  ...,  1.5547e+00,\n",
       "           -1.8047e+00, -1.3516e+00],\n",
       "          [ 6.5918e-02,  2.2852e-01, -1.3770e-01,  ..., -2.4414e-01,\n",
       "           -1.6699e-01,  3.5400e-02],\n",
       "          [ 6.9141e-01, -1.1172e+00, -1.6719e+00,  ..., -2.1582e-01,\n",
       "            4.3750e-01, -1.5859e+00],\n",
       "          ...,\n",
       "          [-4.9805e-01, -3.2227e-01, -8.0859e-01,  ..., -8.5938e-01,\n",
       "           -1.3672e-01, -9.1797e-01],\n",
       "          [ 2.2031e+00, -1.0938e+00, -2.5156e+00,  ..., -4.9805e-01,\n",
       "           -1.8516e+00, -1.3984e+00],\n",
       "          [ 7.1875e-01,  2.2812e+00, -1.7656e+00,  ..., -4.5166e-02,\n",
       "            3.6094e+00, -3.5938e+00]],\n",
       "\n",
       "         [[ 3.4766e-01, -2.3804e-02, -5.7031e-01,  ..., -2.3340e-01,\n",
       "            4.0430e-01,  1.6016e-01],\n",
       "          [ 6.0938e-01,  4.6289e-01,  2.5781e-01,  ...,  1.4648e-01,\n",
       "           -4.9219e-01, -7.4219e-01],\n",
       "          [ 5.6250e-01,  2.9541e-02,  6.9531e-01,  ...,  9.3750e-01,\n",
       "           -5.5469e-01, -1.1797e+00],\n",
       "          ...,\n",
       "          [-7.3828e-01,  8.8281e-01, -2.9531e+00,  ..., -1.2305e-01,\n",
       "           -2.6172e-01,  5.6250e-01],\n",
       "          [-1.4922e+00,  1.2500e+00,  9.1016e-01,  ...,  6.3672e-01,\n",
       "            1.1172e+00, -2.2969e+00],\n",
       "          [-3.1641e-01,  4.5410e-02,  8.0566e-02,  ...,  4.4678e-02,\n",
       "            1.1133e-01, -1.7090e-01]],\n",
       "\n",
       "         [[ 9.9609e-01,  1.3867e-01, -1.6719e+00,  ..., -6.7969e-01,\n",
       "            3.6523e-01,  1.1484e+00],\n",
       "          [-1.9434e-01, -6.5430e-02,  3.8867e-01,  ...,  1.6797e-01,\n",
       "            5.1514e-02, -4.6387e-02],\n",
       "          [-1.4453e+00,  2.7148e-01,  2.5586e-01,  ..., -4.1211e-01,\n",
       "            5.8594e-01,  2.3594e+00],\n",
       "          ...,\n",
       "          [ 9.9609e-01,  1.8457e-01, -2.2812e+00,  ..., -1.4531e+00,\n",
       "           -1.0938e-01, -3.8818e-02],\n",
       "          [-7.7734e-01, -4.0430e-01,  5.8984e-01,  ..., -1.9238e-01,\n",
       "            4.6875e-02, -6.0938e-01],\n",
       "          [ 2.3125e+00,  1.1953e+00, -1.0938e+00,  ..., -5.2734e-01,\n",
       "           -1.9766e+00, -4.2188e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 5.4297e-01, -4.3164e-01, -5.9375e-01,  ...,  5.7031e-01,\n",
       "           -1.5234e-01, -2.5391e-01],\n",
       "          [ 1.8281e+00, -1.2500e+00, -8.9062e-01,  ...,  1.3359e+00,\n",
       "           -6.7188e-01,  5.8203e-01],\n",
       "          [-1.0156e+00,  1.6719e+00,  7.0703e-01,  ..., -4.5898e-01,\n",
       "            8.9453e-01, -1.4844e+00],\n",
       "          ...,\n",
       "          [ 4.8438e-01, -2.1582e-01, -1.1719e+00,  ...,  7.0703e-01,\n",
       "           -3.4766e-01, -1.9922e-01],\n",
       "          [ 6.1328e-01,  1.8555e-01, -1.0703e+00,  ..., -6.0059e-02,\n",
       "           -2.1250e+00, -1.0000e+00],\n",
       "          [-5.4688e-01,  5.8984e-01,  5.9766e-01,  ..., -2.0625e+00,\n",
       "           -1.6953e+00,  1.0703e+00]],\n",
       "\n",
       "         [[ 4.0234e-01,  2.3633e-01, -3.1836e-01,  ..., -3.1250e-01,\n",
       "           -2.8076e-02, -5.8984e-01],\n",
       "          [-8.3984e-01, -1.0156e+00,  4.8584e-02,  ..., -9.0234e-01,\n",
       "           -3.7695e-01, -9.0820e-02],\n",
       "          [-1.1797e+00,  8.7109e-01,  9.3750e-02,  ..., -4.9609e-01,\n",
       "            8.5938e-01,  4.9609e-01],\n",
       "          ...,\n",
       "          [-6.4941e-02, -5.2734e-01, -2.6953e-01,  ..., -7.8125e-02,\n",
       "            7.8613e-02,  4.2969e-01],\n",
       "          [ 8.5938e-01, -1.1641e+00, -1.8750e-01,  ...,  1.2031e+00,\n",
       "           -5.8105e-02, -7.4609e-01],\n",
       "          [ 1.3438e+00, -6.1719e-01, -6.0156e-01,  ...,  5.9766e-01,\n",
       "           -5.3516e-01, -7.5391e-01]],\n",
       "\n",
       "         [[ 1.0596e-01,  3.9453e-01, -1.2402e-01,  ...,  7.1094e-01,\n",
       "            1.1719e-01,  1.2436e-03],\n",
       "          [ 3.0273e-01, -7.4219e-01, -6.0938e-01,  ...,  6.6016e-01,\n",
       "            1.0156e-01,  1.4160e-01],\n",
       "          [ 2.4609e-01, -2.0117e-01, -2.0703e-01,  ..., -7.7344e-01,\n",
       "            7.7148e-02, -2.2339e-02],\n",
       "          ...,\n",
       "          [ 9.5215e-02, -2.2461e-01, -1.7676e-01,  ...,  1.7285e-01,\n",
       "           -2.3242e-01,  5.7129e-02],\n",
       "          [ 2.7656e+00,  5.1172e-01, -1.9375e+00,  ...,  5.0312e+00,\n",
       "           -1.2266e+00, -1.3594e+00],\n",
       "          [-2.6406e+00,  4.7852e-01,  2.8711e-01,  ..., -1.3984e+00,\n",
       "            1.0859e+00, -6.5234e-01]]],\n",
       "\n",
       "\n",
       "        [[[-6.1646e-03, -3.3008e-01,  3.5938e-01,  ..., -9.3262e-02,\n",
       "            2.2852e-01,  6.1719e-01],\n",
       "          [-2.2949e-01, -8.0078e-02,  4.8633e-01,  ..., -1.6562e+00,\n",
       "           -2.1250e+00,  1.8652e-01],\n",
       "          [-8.3496e-02,  3.6523e-01, -1.1016e+00,  ...,  5.3125e-01,\n",
       "            1.5078e+00, -1.1328e+00],\n",
       "          ...,\n",
       "          [-9.5312e-01, -3.6719e-01,  1.0498e-01,  ...,  1.0703e+00,\n",
       "           -3.6914e-01, -1.2109e+00],\n",
       "          [ 5.3516e-01,  7.0703e-01,  7.9297e-01,  ..., -2.2559e-01,\n",
       "           -4.0625e-01,  1.0625e+00],\n",
       "          [-2.0020e-01,  2.1729e-02,  2.0215e-01,  ...,  1.7188e-01,\n",
       "           -2.6758e-01,  6.1523e-02]],\n",
       "\n",
       "         [[-8.4375e-01, -2.0938e+00, -3.3438e+00,  ..., -2.2969e+00,\n",
       "            2.3633e-01, -3.1250e+00],\n",
       "          [ 2.6250e+00, -2.9844e+00, -2.8750e+00,  ..., -2.9492e-01,\n",
       "            1.4062e+00, -3.1094e+00],\n",
       "          [ 7.8125e-01, -2.1250e+00, -1.4297e+00,  ..., -3.3984e-01,\n",
       "            5.2734e-01, -1.5391e+00],\n",
       "          ...,\n",
       "          [ 1.5859e+00,  2.2559e-01, -1.2598e-01,  ...,  2.9375e+00,\n",
       "            3.7305e-01, -4.0938e+00],\n",
       "          [-9.2188e-01,  5.6250e+00,  9.1797e-01,  ...,  1.4688e+00,\n",
       "           -5.0312e+00, -1.6250e+00],\n",
       "          [-1.6895e-01, -4.9805e-01, -2.1582e-01,  ..., -1.1797e+00,\n",
       "            7.2656e-01,  1.5938e+00]],\n",
       "\n",
       "         [[-2.4805e-01,  8.3203e-01,  2.3730e-01,  ..., -1.2031e+00,\n",
       "           -4.8242e-01, -2.7539e-01],\n",
       "          [-8.2031e-01, -1.4844e+00, -2.1562e+00,  ...,  6.4453e-01,\n",
       "            2.0938e+00,  1.1484e+00],\n",
       "          [-1.3125e+00,  2.9102e-01,  1.7109e+00,  ..., -2.0215e-01,\n",
       "           -2.7734e-01,  9.8828e-01],\n",
       "          ...,\n",
       "          [ 1.0742e-01, -1.3574e-01,  2.0703e-01,  ...,  1.1865e-01,\n",
       "           -7.7734e-01,  1.2598e-01],\n",
       "          [ 6.9531e-01, -5.6641e-01,  9.1797e-01,  ...,  7.5391e-01,\n",
       "           -7.8906e-01,  9.0625e-01],\n",
       "          [ 1.6484e+00, -7.5000e-01, -8.7402e-02,  ...,  4.1797e-01,\n",
       "            1.5320e-02,  1.6875e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-5.0391e-01, -7.1875e-01,  5.4297e-01,  ...,  3.1055e-01,\n",
       "           -4.2480e-02, -6.8359e-01],\n",
       "          [-3.5156e-01, -9.3359e-01,  6.6016e-01,  ..., -2.5586e-01,\n",
       "            4.1016e-01, -1.0000e+00],\n",
       "          [ 1.4141e+00, -6.4453e-01,  5.6641e-01,  ..., -4.8828e-01,\n",
       "           -1.2695e-01, -5.9766e-01],\n",
       "          ...,\n",
       "          [ 2.8320e-01,  9.1406e-01, -7.6172e-02,  ...,  2.1289e-01,\n",
       "            1.0254e-01, -5.0000e-01],\n",
       "          [ 6.2109e-01,  5.1562e-01,  1.0312e+00,  ...,  4.2773e-01,\n",
       "            4.2969e-01,  1.0547e+00],\n",
       "          [ 4.0000e+00,  4.1406e-01, -3.4375e+00,  ...,  7.4609e-01,\n",
       "           -3.9688e+00,  4.6562e+00]],\n",
       "\n",
       "         [[-1.9775e-02,  9.1309e-02, -1.5430e-01,  ..., -1.1914e-01,\n",
       "           -1.0303e-01,  1.2305e-01],\n",
       "          [-1.4355e-01, -2.2852e-01, -5.5420e-02,  ..., -7.9102e-02,\n",
       "           -1.0889e-01, -3.1055e-01],\n",
       "          [ 1.1328e+00,  8.0859e-01,  1.0859e+00,  ...,  5.8984e-01,\n",
       "            1.0312e+00,  1.0234e+00],\n",
       "          ...,\n",
       "          [-3.1055e-01, -3.7891e-01, -1.6699e-01,  ..., -1.0791e-01,\n",
       "            1.3672e-01, -2.7188e+00],\n",
       "          [ 7.6562e-01, -7.1484e-01, -4.1406e-01,  ..., -1.1562e+00,\n",
       "           -2.4121e-01, -1.1963e-01],\n",
       "          [-3.8867e-01, -6.2500e-01,  1.0791e-01,  ...,  1.5781e+00,\n",
       "            3.2812e-01, -1.4609e+00]],\n",
       "\n",
       "         [[-1.5312e+00,  1.0312e+00,  2.9062e+00,  ...,  7.1094e-01,\n",
       "           -7.5000e-01, -7.5391e-01],\n",
       "          [ 1.0312e+00, -1.5723e-01, -4.6289e-01,  ...,  7.3828e-01,\n",
       "            3.7305e-01,  7.8516e-01],\n",
       "          [-1.2266e+00,  7.3828e-01, -2.0215e-01,  ...,  2.6001e-02,\n",
       "            3.2227e-01,  2.6758e-01],\n",
       "          ...,\n",
       "          [-4.6875e-01, -1.0469e+00, -1.3984e+00,  ..., -6.1719e-01,\n",
       "            1.1572e-01, -6.9141e-01],\n",
       "          [ 2.3242e-01,  6.2891e-01,  3.7891e-01,  ...,  2.3145e-01,\n",
       "            6.5625e-01,  3.8672e-01],\n",
       "          [-1.2891e-01,  2.0508e-01, -1.6406e+00,  ...,  9.8438e-01,\n",
       "            7.1875e-01,  6.5234e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 4.1199e-03,  3.2471e-02,  4.4189e-02,  ...,  3.3447e-02,\n",
       "            4.0527e-02, -1.1719e-02],\n",
       "          [-7.0801e-02,  7.2266e-01,  3.0859e-01,  ...,  4.0039e-01,\n",
       "            3.0664e-01, -1.1230e-01],\n",
       "          [-2.1289e-01, -3.3594e-01,  1.9141e-01,  ...,  6.8848e-02,\n",
       "           -6.2012e-02,  3.9062e-02],\n",
       "          ...,\n",
       "          [ 4.3750e-01, -2.4121e-01,  4.1211e-01,  ...,  1.4160e-01,\n",
       "           -5.3906e-01,  7.3242e-02],\n",
       "          [ 2.8320e-02, -2.3730e-01,  6.5625e-01,  ...,  2.8906e-01,\n",
       "           -2.1250e+00, -1.2207e-01],\n",
       "          [ 6.4941e-02, -8.6914e-02,  9.1309e-02,  ...,  3.7842e-02,\n",
       "           -1.2012e-01, -7.1777e-02]],\n",
       "\n",
       "         [[-4.8242e-01, -2.7344e-01,  5.9375e-01,  ..., -3.2715e-02,\n",
       "            5.1562e-01,  4.8584e-02],\n",
       "          [-3.5938e-01, -6.6406e-02,  7.0703e-01,  ..., -1.9238e-01,\n",
       "            2.6562e-01,  5.3711e-02],\n",
       "          [ 1.1719e+00,  3.5352e-01,  1.2344e+00,  ..., -1.2188e+00,\n",
       "           -1.5312e+00, -1.5039e-01],\n",
       "          ...,\n",
       "          [-1.1250e+00,  2.2559e-01,  1.5723e-01,  ..., -9.1016e-01,\n",
       "            3.1836e-01,  1.0156e+00],\n",
       "          [-1.8750e+00,  1.6797e+00,  2.6562e-01,  ..., -4.2969e-01,\n",
       "            3.7891e-01, -1.4297e+00],\n",
       "          [-1.9062e+00, -6.0625e+00, -3.5938e-01,  ...,  4.3359e-01,\n",
       "            4.3750e+00, -1.7456e-02]],\n",
       "\n",
       "         [[ 1.9062e+00,  1.0469e+00, -2.6172e-01,  ...,  1.9531e+00,\n",
       "           -2.5391e-01,  1.5391e+00],\n",
       "          [ 1.1406e+00,  5.4688e-01, -1.9727e-01,  ...,  9.5703e-01,\n",
       "           -3.1641e-01,  6.1328e-01],\n",
       "          [-7.0703e-01,  1.2793e-01, -2.6172e-01,  ...,  5.1562e-01,\n",
       "           -5.4297e-01, -6.1719e-01],\n",
       "          ...,\n",
       "          [-1.8984e+00, -2.1582e-01,  1.7188e-01,  ..., -1.6875e+00,\n",
       "           -3.8281e+00, -3.8086e-01],\n",
       "          [ 4.7266e-01, -1.1902e-02,  3.2812e-01,  ...,  6.0156e-01,\n",
       "            1.4844e+00,  2.7539e-01],\n",
       "          [ 1.0859e+00,  6.0547e-01,  5.4688e-01,  ...,  9.2969e-01,\n",
       "            3.3008e-01,  2.0508e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.0303e-01, -1.4844e-01,  4.2188e-01,  ..., -4.4922e-02,\n",
       "           -3.2422e-01, -2.8320e-01],\n",
       "          [-4.6143e-02, -1.9434e-01,  4.0039e-01,  ..., -5.4932e-02,\n",
       "           -4.5703e-01, -8.0566e-02],\n",
       "          [-2.2656e+00, -3.3906e+00, -3.8086e-01,  ..., -1.1719e+00,\n",
       "            1.3047e+00,  2.9688e+00],\n",
       "          ...,\n",
       "          [-1.9609e+00,  1.3477e-01, -1.8066e-02,  ...,  1.4062e+00,\n",
       "           -4.6484e-01,  1.0547e+00],\n",
       "          [-2.0781e+00,  2.7148e-01, -1.7969e+00,  ...,  2.2812e+00,\n",
       "           -1.2207e-01,  1.7344e+00],\n",
       "          [-3.7891e-01,  3.5156e-01, -1.4297e+00,  ...,  2.3242e-01,\n",
       "           -4.6484e-01, -2.2949e-01]],\n",
       "\n",
       "         [[-4.5117e-01, -2.3594e+00, -1.7344e+00,  ...,  3.6094e+00,\n",
       "           -1.5938e+00,  2.1562e+00],\n",
       "          [ 3.9219e+00, -2.4531e+00, -8.8281e-01,  ..., -1.3438e+00,\n",
       "           -1.1094e+00, -8.9062e-01],\n",
       "          [ 6.5430e-02, -5.7812e-01,  1.0859e+00,  ...,  1.9922e+00,\n",
       "           -1.8359e+00,  3.2227e-01],\n",
       "          ...,\n",
       "          [ 9.0820e-02,  7.1289e-02, -1.2969e+00,  ..., -2.3438e-01,\n",
       "            1.4648e-01,  5.6641e-01],\n",
       "          [ 3.9844e-01,  2.7344e-01, -5.3516e-01,  ...,  1.1536e-02,\n",
       "            3.3447e-02,  2.9102e-01],\n",
       "          [ 4.5898e-01,  5.2344e-01,  9.1016e-01,  ..., -1.5820e-01,\n",
       "            1.6094e+00,  3.6133e-01]],\n",
       "\n",
       "         [[-2.9663e-02, -2.2559e-01, -1.3281e-01,  ..., -2.6855e-02,\n",
       "           -4.4434e-02, -3.6133e-02],\n",
       "          [ 1.2695e-01, -1.0645e-01,  7.5684e-02,  ...,  5.0781e-01,\n",
       "            6.4453e-01, -6.1523e-02],\n",
       "          [ 2.1484e-02,  7.6660e-02, -4.1260e-02,  ..., -1.9238e-01,\n",
       "            1.8555e-02, -1.4941e-01],\n",
       "          ...,\n",
       "          [ 3.2969e+00,  1.9062e+00,  2.0938e+00,  ...,  2.6250e+00,\n",
       "            6.7578e-01,  2.6953e-01],\n",
       "          [-1.1182e-01, -3.7305e-01,  1.6602e-01,  ...,  3.5547e-01,\n",
       "           -5.9814e-02, -6.8750e-01],\n",
       "          [-7.2266e-02,  8.9453e-01, -6.5234e-01,  ..., -9.5703e-01,\n",
       "            1.1621e-01, -7.6172e-02]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-1.3184e-02, -1.8311e-02, -1.0681e-02,  ..., -5.8289e-03,\n",
       "            7.7820e-04,  5.3711e-03],\n",
       "          [-1.0452e-03, -2.3071e-02,  1.6968e-02,  ..., -6.8359e-02,\n",
       "           -1.2329e-02, -1.0645e-01],\n",
       "          [ 5.2344e-01,  2.6953e-01, -4.8828e-01,  ...,  5.2734e-01,\n",
       "           -1.7383e-01,  5.2979e-02],\n",
       "          ...,\n",
       "          [ 4.2812e+00, -1.1172e+00,  7.4609e-01,  ...,  2.5195e-01,\n",
       "            3.4375e+00,  2.1250e+00],\n",
       "          [ 1.3750e+00, -9.6094e-01,  1.0781e+00,  ...,  1.4453e+00,\n",
       "            7.3438e-01,  2.9844e+00],\n",
       "          [-1.0300e-03, -2.5146e-02, -1.0059e-01,  ..., -5.7031e-01,\n",
       "            4.7656e-01,  6.5613e-03]],\n",
       "\n",
       "         [[-6.1768e-02,  2.6123e-02, -8.7280e-03,  ..., -1.2634e-02,\n",
       "           -3.1128e-02,  9.7046e-03],\n",
       "          [ 5.1875e+00, -2.9375e+00,  3.3984e-01,  ...,  1.2422e+00,\n",
       "            6.7969e-01, -3.6562e+00],\n",
       "          [-1.2500e+00,  5.1953e-01, -1.6211e-01,  ..., -2.3047e-01,\n",
       "           -5.9375e-01,  2.5586e-01],\n",
       "          ...,\n",
       "          [-1.3906e+00,  1.6699e-01,  1.2031e+00,  ..., -9.3994e-03,\n",
       "            6.7969e-01,  7.5781e-01],\n",
       "          [ 1.3438e+00, -1.3750e+00,  1.2656e+00,  ..., -8.4375e-01,\n",
       "           -6.0156e-01,  3.4180e-01],\n",
       "          [ 8.6328e-01, -1.1172e+00,  2.3145e-01,  ..., -1.5781e+00,\n",
       "           -1.0625e+00, -2.1680e-01]],\n",
       "\n",
       "         [[-4.5312e-01, -9.4238e-02,  4.6289e-01,  ..., -6.6797e-01,\n",
       "           -3.0469e-01,  7.7209e-03],\n",
       "          [ 2.1387e-01, -1.1621e-01,  3.7305e-01,  ...,  1.4941e-01,\n",
       "           -9.7656e-01, -1.2354e-01],\n",
       "          [ 3.4668e-02, -2.0752e-02,  1.8359e-01,  ..., -7.5195e-02,\n",
       "           -3.5938e-01, -1.6968e-02],\n",
       "          ...,\n",
       "          [ 1.8457e-01,  2.1777e-01,  9.1797e-01,  ..., -2.1875e-01,\n",
       "            5.3125e-01, -4.8633e-01],\n",
       "          [-2.9492e-01,  2.0996e-01, -1.0625e+00,  ...,  8.9062e-01,\n",
       "           -1.4453e-01,  3.3008e-01],\n",
       "          [ 8.2031e-02, -3.5547e-01, -6.9141e-01,  ...,  8.0859e-01,\n",
       "           -1.3245e-02, -3.1641e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.3428e-02, -3.6865e-02, -1.9531e-02,  ...,  2.0264e-02,\n",
       "           -1.7578e-02,  5.0049e-03],\n",
       "          [ 1.3125e+00,  3.1836e-01,  4.7266e-01,  ...,  1.1250e+00,\n",
       "           -1.0859e+00, -5.4443e-02],\n",
       "          [ 1.2344e+00,  1.2812e+00,  8.2031e-01,  ...,  8.3594e-01,\n",
       "           -7.8906e-01, -1.4746e-01],\n",
       "          ...,\n",
       "          [-1.8828e+00, -1.6719e+00, -1.2656e+00,  ...,  8.8281e-01,\n",
       "           -5.7031e-01,  2.7539e-01],\n",
       "          [-5.7031e-01,  4.5508e-01,  1.7871e-01,  ...,  3.9648e-01,\n",
       "            1.2891e-01,  3.6133e-01],\n",
       "          [-5.1172e-01,  1.0547e+00, -5.1270e-02,  ...,  1.1780e-02,\n",
       "            5.6250e-01,  1.3184e-02]],\n",
       "\n",
       "         [[ 2.7148e-01, -2.1387e-01,  2.0020e-01,  ..., -2.4609e-01,\n",
       "           -4.6387e-02,  2.9492e-01],\n",
       "          [ 4.2773e-01, -2.5195e-01,  3.6328e-01,  ..., -4.8828e-01,\n",
       "           -6.1768e-02,  4.3164e-01],\n",
       "          [-1.0596e-01,  4.9609e-01,  1.9141e+00,  ...,  1.4062e-01,\n",
       "           -1.7188e+00, -1.1484e+00],\n",
       "          ...,\n",
       "          [-4.7656e-01, -4.8633e-01,  1.5078e+00,  ...,  3.8281e-01,\n",
       "            3.1445e-01, -5.7422e-01],\n",
       "          [ 1.1016e+00, -1.0107e-01, -1.8188e-02,  ...,  1.0938e+00,\n",
       "           -1.3672e+00, -2.1250e+00],\n",
       "          [ 6.0547e-01,  2.9297e-01, -7.2266e-02,  ...,  6.2109e-01,\n",
       "           -6.4453e-01, -1.4531e+00]],\n",
       "\n",
       "         [[ 4.1406e-01,  9.5703e-02, -1.0234e+00,  ...,  4.9609e-01,\n",
       "           -1.5312e+00, -1.8359e+00],\n",
       "          [ 7.6953e-01, -9.9487e-03, -1.2891e+00,  ...,  8.3594e-01,\n",
       "           -2.4121e-01,  4.9805e-01],\n",
       "          [ 8.2422e-01,  5.5469e-01,  3.4180e-01,  ..., -1.8457e-01,\n",
       "            3.0151e-02,  9.9609e-01],\n",
       "          ...,\n",
       "          [-6.0547e-01, -3.6523e-01,  1.3750e+00,  ..., -8.0859e-01,\n",
       "           -1.8047e+00,  3.0312e+00],\n",
       "          [ 8.0078e-02, -8.5938e-02, -1.1670e-01,  ..., -4.9805e-02,\n",
       "            2.2168e-01, -1.1475e-01],\n",
       "          [-3.2959e-02,  3.2227e-01,  3.4766e-01,  ...,  5.5859e-01,\n",
       "           -2.1387e-01,  2.3730e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 4.0625e-01, -4.8438e-01, -6.5430e-02,  ...,  5.2344e-01,\n",
       "           -3.4375e-01,  1.2500e-01],\n",
       "          [-4.2578e-01,  4.6680e-01, -7.0801e-02,  ..., -1.9043e-01,\n",
       "            5.0049e-02, -2.8516e-01],\n",
       "          [-1.3906e+00, -6.9531e-01, -6.8359e-01,  ..., -2.8125e-01,\n",
       "            1.7188e+00,  1.1641e+00],\n",
       "          ...,\n",
       "          [ 2.0781e+00, -1.5703e+00,  2.3281e+00,  ..., -2.5469e+00,\n",
       "            1.4375e+00, -7.1094e-01],\n",
       "          [ 9.2773e-02, -2.5977e-01,  4.0039e-01,  ..., -1.6992e-01,\n",
       "            2.9688e-01, -1.2512e-03],\n",
       "          [ 6.3672e-01, -1.1641e+00,  1.3281e+00,  ..., -1.3906e+00,\n",
       "            1.6328e+00, -9.0820e-02]],\n",
       "\n",
       "         [[ 3.6719e-01, -7.0703e-01,  1.0303e-01,  ...,  2.3438e-01,\n",
       "            7.6172e-02, -1.1816e-01],\n",
       "          [ 1.0781e+00, -8.9844e-01, -1.9336e-01,  ..., -1.2969e+00,\n",
       "            4.3945e-01, -1.1016e+00],\n",
       "          [-7.2656e-01, -1.7344e+00, -8.6719e-01,  ...,  2.6758e-01,\n",
       "            2.9492e-01, -6.3672e-01],\n",
       "          ...,\n",
       "          [-2.6562e-01,  1.6328e+00,  3.8477e-01,  ..., -3.1836e-01,\n",
       "           -5.1562e-01, -6.7578e-01],\n",
       "          [-3.1982e-02,  8.1055e-02,  7.2327e-03,  ...,  3.4180e-02,\n",
       "            2.4707e-01,  2.6562e-01],\n",
       "          [ 8.6328e-01, -4.9609e-01, -3.1719e+00,  ..., -3.3438e+00,\n",
       "           -1.1875e+00, -4.2812e+00]],\n",
       "\n",
       "         [[ 2.8906e+00,  1.8906e+00,  2.0625e+00,  ...,  2.8281e+00,\n",
       "            8.2812e-01,  2.3906e+00],\n",
       "          [ 1.3984e+00,  2.6367e-01,  9.0234e-01,  ...,  1.1172e+00,\n",
       "           -1.3672e+00, -4.0430e-01],\n",
       "          [ 1.1016e+00,  7.2266e-02,  7.5684e-02,  ..., -3.0029e-02,\n",
       "           -2.9688e-01,  3.0078e-01],\n",
       "          ...,\n",
       "          [-2.8438e+00, -1.3750e+00, -2.2031e+00,  ...,  1.1875e+00,\n",
       "            1.0469e+00,  9.0625e-01],\n",
       "          [ 1.2422e+00,  3.5352e-01,  6.9922e-01,  ..., -7.8906e-01,\n",
       "           -2.6562e-01, -7.3438e-01],\n",
       "          [ 1.7891e+00, -3.0078e-01,  8.4766e-01,  ...,  1.1016e+00,\n",
       "            1.2734e+00,  4.3359e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.0000e+00,  6.9531e-01, -1.1406e+00,  ...,  6.1719e-01,\n",
       "            6.4453e-02,  7.7734e-01],\n",
       "          [ 1.5547e+00,  1.2500e-01, -2.0312e-01,  ...,  2.3682e-02,\n",
       "            3.5742e-01,  1.5156e+00],\n",
       "          [ 7.1094e-01,  1.4688e+00,  5.4688e-01,  ..., -1.1953e+00,\n",
       "           -1.8438e+00,  1.2422e+00],\n",
       "          ...,\n",
       "          [ 8.5156e-01,  4.5312e-01,  4.0430e-01,  ...,  5.5859e-01,\n",
       "            9.4922e-01, -2.8320e-01],\n",
       "          [ 3.1250e+00,  2.0630e-02,  1.7266e+00,  ...,  4.8242e-01,\n",
       "            2.8750e+00,  1.0391e+00],\n",
       "          [-4.4727e-01,  4.3945e-01,  1.3672e+00,  ..., -1.2422e+00,\n",
       "           -1.7344e+00, -1.9062e+00]],\n",
       "\n",
       "         [[ 7.4707e-02, -9.9487e-03, -4.8340e-02,  ...,  3.1445e-01,\n",
       "            1.0889e-01,  1.2012e-01],\n",
       "          [-9.1797e-02,  2.7222e-02, -1.8652e-01,  ...,  3.1250e-01,\n",
       "            1.8066e-01,  3.2812e-01],\n",
       "          [-6.7969e-01,  1.5703e+00,  2.0215e-01,  ...,  4.2236e-02,\n",
       "           -9.0234e-01, -4.8633e-01],\n",
       "          ...,\n",
       "          [-1.9922e+00, -4.1992e-01, -3.2422e-01,  ...,  4.0234e-01,\n",
       "           -7.3047e-01, -1.7109e+00],\n",
       "          [-1.0547e+00, -6.5918e-02, -9.8828e-01,  ...,  4.1016e-02,\n",
       "            3.8867e-01,  1.7578e-01],\n",
       "          [-4.2500e+00,  4.5471e-03,  4.2188e+00,  ..., -5.5859e-01,\n",
       "           -1.4609e+00,  2.0996e-01]],\n",
       "\n",
       "         [[ 2.2461e-02, -8.9355e-02, -3.4180e-02,  ...,  4.9072e-02,\n",
       "           -2.6367e-02, -4.3701e-02],\n",
       "          [-2.6758e-01,  8.8281e-01,  4.8242e-01,  ..., -2.9492e-01,\n",
       "            3.2617e-01,  1.0645e-01],\n",
       "          [-1.6113e-01,  2.3633e-01, -3.3594e-01,  ...,  5.8594e-01,\n",
       "           -7.5391e-01, -6.8750e-01],\n",
       "          ...,\n",
       "          [ 3.3438e+00, -3.0938e+00,  2.0938e+00,  ..., -3.0312e+00,\n",
       "           -1.9297e+00, -3.2812e+00],\n",
       "          [-1.7578e+00,  1.6875e+00, -1.8906e+00,  ...,  5.4062e+00,\n",
       "            9.7656e-01,  4.1562e+00],\n",
       "          [-4.1016e-01,  2.1094e+00, -4.3359e-01,  ..., -1.7656e+00,\n",
       "            3.1445e-01,  4.0527e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 1.7266e+00, -7.2266e-01,  2.8320e-01,  ...,  9.7266e-01,\n",
       "            6.0547e-01, -6.4844e-01],\n",
       "          [-1.6797e+00, -5.3906e-01, -3.1250e-02,  ...,  1.3047e+00,\n",
       "           -3.9062e-01, -3.8125e+00],\n",
       "          [ 4.7461e-01, -1.2812e+00,  1.1797e+00,  ..., -7.1875e-01,\n",
       "           -3.3281e+00,  9.1797e-01],\n",
       "          ...,\n",
       "          [-1.0107e-01,  5.9570e-02,  1.6699e-01,  ..., -3.1836e-01,\n",
       "            2.9492e-01,  1.6797e-01],\n",
       "          [-2.9449e-03,  6.6797e-01, -8.2812e-01,  ..., -7.1777e-02,\n",
       "            7.9102e-02,  1.3867e-01],\n",
       "          [-1.3184e-01, -2.0156e+00,  5.6641e-01,  ...,  7.9590e-02,\n",
       "            3.0469e-01,  1.1250e+00]],\n",
       "\n",
       "         [[ 1.9336e-01,  4.5312e-01,  1.1094e+00,  ..., -4.6875e-02,\n",
       "           -8.2812e-01, -4.6680e-01],\n",
       "          [-1.4219e+00,  4.4062e+00, -7.3047e-01,  ..., -4.8096e-02,\n",
       "            7.1094e-01,  2.0312e+00],\n",
       "          [-5.2344e-01,  3.1094e+00, -2.3633e-01,  ..., -4.7266e-01,\n",
       "            2.3750e+00,  6.7969e-01],\n",
       "          ...,\n",
       "          [ 1.1875e+00, -1.8750e-01, -9.7266e-01,  ..., -2.0156e+00,\n",
       "            3.7598e-02,  2.0215e-01],\n",
       "          [ 4.2578e-01,  6.9922e-01, -1.2656e+00,  ...,  1.4531e+00,\n",
       "            3.7188e+00,  1.2988e-01],\n",
       "          [ 2.5269e-02, -2.4512e-01,  6.4062e-01,  ..., -6.9141e-01,\n",
       "           -2.1875e+00, -4.7852e-01]],\n",
       "\n",
       "         [[-9.3262e-02,  1.7776e-03, -1.4160e-01,  ..., -8.0566e-02,\n",
       "            9.1797e-02, -5.0293e-02],\n",
       "          [ 4.7119e-02, -1.1182e-01,  5.9375e-01,  ...,  3.5156e-01,\n",
       "           -6.0547e-01,  2.8906e-01],\n",
       "          [-1.8047e+00,  9.6094e-01, -1.2061e-01,  ...,  8.5547e-01,\n",
       "           -3.8086e-01, -7.3730e-02],\n",
       "          ...,\n",
       "          [-8.5938e-02,  2.1094e+00, -1.2891e+00,  ..., -4.7266e-01,\n",
       "            5.5469e-01,  5.4932e-02],\n",
       "          [-1.3359e+00, -1.7578e+00, -2.0156e+00,  ..., -9.6094e-01,\n",
       "           -5.1562e-01, -1.7656e+00],\n",
       "          [ 1.8359e-01,  1.5137e-01,  3.1055e-01,  ...,  1.3281e-01,\n",
       "           -6.0059e-02,  2.6953e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.5000e-01, -4.8242e-01, -2.5781e-01,  ...,  3.2812e-01,\n",
       "           -5.9766e-01, -5.7602e-04],\n",
       "          [ 4.0430e-01, -1.5234e-01, -8.7891e-01,  ..., -4.2578e-01,\n",
       "           -8.2031e-01, -7.2266e-01],\n",
       "          [ 9.9219e-01, -1.2891e+00,  1.0625e+00,  ...,  9.0234e-01,\n",
       "            3.2422e-01,  1.3984e+00],\n",
       "          ...,\n",
       "          [ 2.2969e+00,  6.1250e+00, -1.7090e-01,  ..., -4.8125e+00,\n",
       "           -1.3984e+00,  1.8516e+00],\n",
       "          [-2.0781e+00, -6.4062e-01,  1.9434e-01,  ...,  6.9141e-01,\n",
       "            8.7500e-01,  1.2734e+00],\n",
       "          [ 2.9102e-01, -1.5469e+00,  1.0703e+00,  ...,  1.8594e+00,\n",
       "           -1.6250e+00,  5.0781e-01]],\n",
       "\n",
       "         [[ 2.5586e-01,  2.4219e-01, -3.3203e-01,  ...,  2.3438e-01,\n",
       "           -7.2656e-01, -1.9043e-01],\n",
       "          [-6.2500e-01, -1.4258e-01,  4.0039e-01,  ..., -1.7090e-02,\n",
       "            1.3906e+00,  1.1406e+00],\n",
       "          [ 1.4688e+00, -8.6719e-01,  3.9258e-01,  ..., -1.1328e+00,\n",
       "           -1.5078e+00, -3.7031e+00],\n",
       "          ...,\n",
       "          [-4.8242e-01, -2.0625e+00, -1.8750e-01,  ...,  5.5859e-01,\n",
       "            6.8359e-01,  1.4221e-02],\n",
       "          [-8.1055e-02,  4.1016e-01, -1.7109e+00,  ...,  1.1641e+00,\n",
       "           -1.0781e+00, -1.1953e+00],\n",
       "          [ 2.4805e-01,  1.0596e-01,  2.4023e-01,  ...,  1.6895e-01,\n",
       "           -5.8105e-02, -4.9561e-02]],\n",
       "\n",
       "         [[-4.5000e+00,  9.4922e-01, -1.2969e+00,  ...,  9.8145e-02,\n",
       "           -2.2852e-01, -8.6719e-01],\n",
       "          [-6.1768e-02,  8.5938e-01,  2.4062e+00,  ..., -2.4536e-02,\n",
       "           -1.0312e+00,  9.3359e-01],\n",
       "          [-2.4121e-01, -7.4219e-01,  5.5078e-01,  ...,  2.9102e-01,\n",
       "            2.4512e-01, -1.3770e-01],\n",
       "          ...,\n",
       "          [-1.3984e+00,  9.8145e-02,  7.6953e-01,  ..., -3.8281e-01,\n",
       "            6.6406e-01,  5.1562e-01],\n",
       "          [-1.5156e+00, -5.5078e-01,  1.6172e+00,  ...,  1.7090e-01,\n",
       "            1.2656e+00,  1.0312e+00],\n",
       "          [-2.5156e+00, -2.5156e+00, -2.6953e-01,  ...,  9.9609e-02,\n",
       "           -5.0312e+00,  7.0703e-01]]]], device='cuda:0', dtype=torch.bfloat16,\n",
       "       grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1390398d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1.1328e+00, -2.7188e+00,  5.2188e+00,  ...,  1.5547e+00,\n",
       "           -1.8047e+00, -1.3516e+00],\n",
       "          [ 6.5918e-02,  2.2852e-01, -1.3770e-01,  ..., -2.4414e-01,\n",
       "           -1.6699e-01,  3.5400e-02],\n",
       "          [ 6.9141e-01, -1.1172e+00, -1.6719e+00,  ..., -2.1582e-01,\n",
       "            4.3750e-01, -1.5859e+00],\n",
       "          ...,\n",
       "          [-4.9805e-01, -3.2422e-01, -8.0859e-01,  ..., -8.5938e-01,\n",
       "           -1.3672e-01, -9.1797e-01],\n",
       "          [ 2.2031e+00, -1.0938e+00, -2.5156e+00,  ..., -5.0000e-01,\n",
       "           -1.8516e+00, -1.3906e+00],\n",
       "          [ 7.1484e-01,  2.2969e+00, -1.7578e+00,  ..., -4.6387e-02,\n",
       "            3.6094e+00, -3.5938e+00]],\n",
       "\n",
       "         [[ 3.4766e-01, -2.3804e-02, -5.7031e-01,  ..., -2.3340e-01,\n",
       "            4.0430e-01,  1.6016e-01],\n",
       "          [ 6.0938e-01,  4.6289e-01,  2.5781e-01,  ...,  1.4648e-01,\n",
       "           -4.9219e-01, -7.4219e-01],\n",
       "          [ 5.6250e-01,  2.9663e-02,  6.9531e-01,  ...,  9.3750e-01,\n",
       "           -5.5469e-01, -1.1797e+00],\n",
       "          ...,\n",
       "          [-7.4219e-01,  8.7891e-01, -2.9531e+00,  ..., -1.1816e-01,\n",
       "           -2.7148e-01,  5.6250e-01],\n",
       "          [-1.4922e+00,  1.2500e+00,  9.1016e-01,  ...,  6.3672e-01,\n",
       "            1.1172e+00, -2.2969e+00],\n",
       "          [-3.1641e-01,  4.5410e-02,  8.0078e-02,  ...,  4.4678e-02,\n",
       "            1.1133e-01, -1.7090e-01]],\n",
       "\n",
       "         [[ 9.9609e-01,  1.3867e-01, -1.6719e+00,  ..., -6.7969e-01,\n",
       "            3.6523e-01,  1.1484e+00],\n",
       "          [-1.9434e-01, -6.5430e-02,  3.8867e-01,  ...,  1.6797e-01,\n",
       "            5.1514e-02, -4.7119e-02],\n",
       "          [-1.4531e+00,  2.7148e-01,  2.5781e-01,  ..., -4.1211e-01,\n",
       "            5.8594e-01,  2.3594e+00],\n",
       "          ...,\n",
       "          [ 1.0000e+00,  1.8164e-01, -2.2812e+00,  ..., -1.4609e+00,\n",
       "           -1.0889e-01, -3.6133e-02],\n",
       "          [-7.7734e-01, -4.0430e-01,  5.8984e-01,  ..., -1.9238e-01,\n",
       "            4.6875e-02, -6.0938e-01],\n",
       "          [ 2.3125e+00,  1.2031e+00, -1.0938e+00,  ..., -5.2734e-01,\n",
       "           -1.9766e+00, -4.1992e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 5.4297e-01, -4.3164e-01, -5.9375e-01,  ...,  5.7031e-01,\n",
       "           -1.5234e-01, -2.5391e-01],\n",
       "          [ 1.8281e+00, -1.2500e+00, -8.9062e-01,  ...,  1.3359e+00,\n",
       "           -6.7188e-01,  5.8203e-01],\n",
       "          [-1.0156e+00,  1.6719e+00,  7.0703e-01,  ..., -4.5898e-01,\n",
       "            8.9453e-01, -1.4844e+00],\n",
       "          ...,\n",
       "          [ 4.8438e-01, -2.1582e-01, -1.1719e+00,  ...,  7.0703e-01,\n",
       "           -3.4766e-01, -1.9922e-01],\n",
       "          [ 6.0938e-01,  1.8750e-01, -1.0703e+00,  ..., -6.2500e-02,\n",
       "           -2.1250e+00, -1.0000e+00],\n",
       "          [-5.4688e-01,  5.8984e-01,  6.0156e-01,  ..., -2.0625e+00,\n",
       "           -1.6953e+00,  1.0703e+00]],\n",
       "\n",
       "         [[ 4.0234e-01,  2.3633e-01, -3.1836e-01,  ..., -3.1250e-01,\n",
       "           -2.8076e-02, -5.8984e-01],\n",
       "          [-8.3984e-01, -1.0156e+00,  4.8584e-02,  ..., -9.0234e-01,\n",
       "           -3.7695e-01, -9.0820e-02],\n",
       "          [-1.1797e+00,  8.7109e-01,  9.3750e-02,  ..., -4.9609e-01,\n",
       "            8.5938e-01,  4.9609e-01],\n",
       "          ...,\n",
       "          [-6.5430e-02, -5.2734e-01, -2.6953e-01,  ..., -7.8125e-02,\n",
       "            7.8613e-02,  4.2969e-01],\n",
       "          [ 8.5938e-01, -1.1641e+00, -1.8945e-01,  ...,  1.2031e+00,\n",
       "           -5.7617e-02, -7.4219e-01],\n",
       "          [ 1.3438e+00, -6.1719e-01, -6.0156e-01,  ...,  5.9766e-01,\n",
       "           -5.3516e-01, -7.5391e-01]],\n",
       "\n",
       "         [[ 1.0596e-01,  3.9453e-01, -1.2402e-01,  ...,  7.1094e-01,\n",
       "            1.1719e-01,  1.2436e-03],\n",
       "          [ 3.0273e-01, -7.4219e-01, -6.0938e-01,  ...,  6.6016e-01,\n",
       "            1.0156e-01,  1.4160e-01],\n",
       "          [ 2.4609e-01, -2.0117e-01, -2.0703e-01,  ..., -7.7344e-01,\n",
       "            7.7148e-02, -2.2339e-02],\n",
       "          ...,\n",
       "          [ 9.4727e-02, -2.2461e-01, -1.7676e-01,  ...,  1.7383e-01,\n",
       "           -2.3242e-01,  5.6885e-02],\n",
       "          [ 2.7656e+00,  5.0781e-01, -1.9297e+00,  ...,  5.0312e+00,\n",
       "           -1.2344e+00, -1.3516e+00],\n",
       "          [-2.6562e+00,  4.7656e-01,  2.8906e-01,  ..., -1.4062e+00,\n",
       "            1.0859e+00, -6.5625e-01]]],\n",
       "\n",
       "\n",
       "        [[[-6.1646e-03, -3.3008e-01,  3.5938e-01,  ..., -9.3262e-02,\n",
       "            2.2852e-01,  6.1719e-01],\n",
       "          [-2.2949e-01, -8.0078e-02,  4.8633e-01,  ..., -1.6562e+00,\n",
       "           -2.1250e+00,  1.8652e-01],\n",
       "          [-8.3496e-02,  3.6719e-01, -1.1094e+00,  ...,  5.3125e-01,\n",
       "            1.5078e+00, -1.1328e+00],\n",
       "          ...,\n",
       "          [-9.5312e-01, -3.6719e-01,  1.0498e-01,  ...,  1.0703e+00,\n",
       "           -3.6914e-01, -1.2109e+00],\n",
       "          [ 5.3516e-01,  7.0703e-01,  7.9297e-01,  ..., -2.2559e-01,\n",
       "           -4.0625e-01,  1.0625e+00],\n",
       "          [-2.0117e-01,  2.0752e-02,  2.0117e-01,  ...,  1.7285e-01,\n",
       "           -2.6758e-01,  5.9814e-02]],\n",
       "\n",
       "         [[-8.4375e-01, -2.0938e+00, -3.3438e+00,  ..., -2.2969e+00,\n",
       "            2.3633e-01, -3.1250e+00],\n",
       "          [ 2.6250e+00, -2.9844e+00, -2.8750e+00,  ..., -2.9492e-01,\n",
       "            1.4062e+00, -3.1094e+00],\n",
       "          [ 7.8125e-01, -2.1250e+00, -1.4297e+00,  ..., -3.3984e-01,\n",
       "            5.2734e-01, -1.5391e+00],\n",
       "          ...,\n",
       "          [ 1.5859e+00,  2.2559e-01, -1.2598e-01,  ...,  2.9375e+00,\n",
       "            3.7305e-01, -4.0938e+00],\n",
       "          [-9.2188e-01,  5.6250e+00,  9.1797e-01,  ...,  1.4688e+00,\n",
       "           -5.0312e+00, -1.6250e+00],\n",
       "          [-1.6895e-01, -4.9805e-01, -2.1582e-01,  ..., -1.1797e+00,\n",
       "            7.2656e-01,  1.5938e+00]],\n",
       "\n",
       "         [[-2.4805e-01,  8.3203e-01,  2.3730e-01,  ..., -1.2031e+00,\n",
       "           -4.8242e-01, -2.7539e-01],\n",
       "          [-8.2031e-01, -1.4844e+00, -2.1562e+00,  ...,  6.4453e-01,\n",
       "            2.0938e+00,  1.1484e+00],\n",
       "          [-1.3125e+00,  2.9102e-01,  1.7109e+00,  ..., -2.0215e-01,\n",
       "           -2.7734e-01,  9.8828e-01],\n",
       "          ...,\n",
       "          [ 1.0791e-01, -1.3574e-01,  2.0703e-01,  ...,  1.1865e-01,\n",
       "           -7.7344e-01,  1.2695e-01],\n",
       "          [ 6.9531e-01, -5.6641e-01,  9.1406e-01,  ...,  7.5391e-01,\n",
       "           -7.9297e-01,  9.0625e-01],\n",
       "          [ 1.6484e+00, -7.5000e-01, -8.7402e-02,  ...,  4.1797e-01,\n",
       "            1.4526e-02,  1.6875e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-5.0391e-01, -7.1875e-01,  5.4297e-01,  ...,  3.1055e-01,\n",
       "           -4.2480e-02, -6.8359e-01],\n",
       "          [-3.5156e-01, -9.3359e-01,  6.6016e-01,  ..., -2.5586e-01,\n",
       "            4.1016e-01, -1.0000e+00],\n",
       "          [ 1.4141e+00, -6.4453e-01,  5.6641e-01,  ..., -4.8828e-01,\n",
       "           -1.2695e-01, -5.9766e-01],\n",
       "          ...,\n",
       "          [ 2.8320e-01,  9.1406e-01, -7.6172e-02,  ...,  2.1387e-01,\n",
       "            9.9609e-02, -5.0391e-01],\n",
       "          [ 6.2109e-01,  5.1562e-01,  1.0312e+00,  ...,  4.2773e-01,\n",
       "            4.2969e-01,  1.0547e+00],\n",
       "          [ 4.0000e+00,  4.1406e-01, -3.4375e+00,  ...,  7.4609e-01,\n",
       "           -3.9688e+00,  4.6562e+00]],\n",
       "\n",
       "         [[-1.9775e-02,  9.1309e-02, -1.5430e-01,  ..., -1.1914e-01,\n",
       "           -1.0303e-01,  1.2305e-01],\n",
       "          [-1.4355e-01, -2.2852e-01, -5.5176e-02,  ..., -7.8613e-02,\n",
       "           -1.0889e-01, -3.1055e-01],\n",
       "          [ 1.1328e+00,  8.0859e-01,  1.0859e+00,  ...,  5.8984e-01,\n",
       "            1.0312e+00,  1.0234e+00],\n",
       "          ...,\n",
       "          [-3.0859e-01, -3.8281e-01, -1.6602e-01,  ..., -1.0840e-01,\n",
       "            1.3770e-01, -2.7188e+00],\n",
       "          [ 7.6562e-01, -7.1484e-01, -4.1406e-01,  ..., -1.1484e+00,\n",
       "           -2.4414e-01, -1.1914e-01],\n",
       "          [-3.9062e-01, -6.2500e-01,  1.0791e-01,  ...,  1.5781e+00,\n",
       "            3.2812e-01, -1.4609e+00]],\n",
       "\n",
       "         [[-1.5312e+00,  1.0312e+00,  2.9062e+00,  ...,  7.1094e-01,\n",
       "           -7.5000e-01, -7.5391e-01],\n",
       "          [ 1.0312e+00, -1.5723e-01, -4.6289e-01,  ...,  7.3828e-01,\n",
       "            3.7305e-01,  7.8516e-01],\n",
       "          [-1.2266e+00,  7.3828e-01, -2.0117e-01,  ...,  2.6123e-02,\n",
       "            3.2227e-01,  2.6758e-01],\n",
       "          ...,\n",
       "          [-4.6875e-01, -1.0547e+00, -1.3984e+00,  ..., -6.1719e-01,\n",
       "            1.1377e-01, -6.9141e-01],\n",
       "          [ 2.3242e-01,  6.2891e-01,  3.7891e-01,  ...,  2.3242e-01,\n",
       "            6.5625e-01,  3.8672e-01],\n",
       "          [-1.2891e-01,  2.0215e-01, -1.6484e+00,  ...,  9.8438e-01,\n",
       "            7.2266e-01,  6.5625e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 4.1199e-03,  3.2471e-02,  4.4189e-02,  ...,  3.3447e-02,\n",
       "            4.0527e-02, -1.1719e-02],\n",
       "          [-7.0801e-02,  7.2266e-01,  3.0859e-01,  ...,  4.0039e-01,\n",
       "            3.0664e-01, -1.1230e-01],\n",
       "          [-2.1289e-01, -3.3594e-01,  1.9141e-01,  ...,  6.8848e-02,\n",
       "           -6.2012e-02,  3.9062e-02],\n",
       "          ...,\n",
       "          [ 4.3750e-01, -2.4121e-01,  4.1211e-01,  ...,  1.4160e-01,\n",
       "           -5.3906e-01,  7.3242e-02],\n",
       "          [ 2.7222e-02, -2.3828e-01,  6.5625e-01,  ...,  2.8906e-01,\n",
       "           -2.1406e+00, -1.2354e-01],\n",
       "          [ 6.5430e-02, -8.6914e-02,  9.1309e-02,  ...,  3.7842e-02,\n",
       "           -1.2012e-01, -7.2266e-02]],\n",
       "\n",
       "         [[-4.8242e-01, -2.7344e-01,  5.9375e-01,  ..., -3.2715e-02,\n",
       "            5.1562e-01,  4.8584e-02],\n",
       "          [-3.5938e-01, -6.6406e-02,  7.0703e-01,  ..., -1.9238e-01,\n",
       "            2.6562e-01,  5.3711e-02],\n",
       "          [ 1.1719e+00,  3.5352e-01,  1.2344e+00,  ..., -1.2188e+00,\n",
       "           -1.5312e+00, -1.5039e-01],\n",
       "          ...,\n",
       "          [-1.1250e+00,  2.2559e-01,  1.5723e-01,  ..., -9.1016e-01,\n",
       "            3.1836e-01,  1.0156e+00],\n",
       "          [-1.8750e+00,  1.6797e+00,  2.6562e-01,  ..., -4.2969e-01,\n",
       "            3.7891e-01, -1.4297e+00],\n",
       "          [-1.9062e+00, -6.0625e+00, -3.5938e-01,  ...,  4.3359e-01,\n",
       "            4.3750e+00, -1.7212e-02]],\n",
       "\n",
       "         [[ 1.9062e+00,  1.0469e+00, -2.6172e-01,  ...,  1.9531e+00,\n",
       "           -2.5391e-01,  1.5391e+00],\n",
       "          [ 1.1484e+00,  5.5078e-01, -1.9824e-01,  ...,  9.6484e-01,\n",
       "           -3.1641e-01,  6.2109e-01],\n",
       "          [-7.0703e-01,  1.2793e-01, -2.6172e-01,  ...,  5.1562e-01,\n",
       "           -5.4297e-01, -6.1719e-01],\n",
       "          ...,\n",
       "          [-1.8984e+00, -2.1582e-01,  1.7285e-01,  ..., -1.6875e+00,\n",
       "           -3.8281e+00, -3.8086e-01],\n",
       "          [ 4.7266e-01, -1.2146e-02,  3.2812e-01,  ...,  6.0156e-01,\n",
       "            1.4766e+00,  2.7539e-01],\n",
       "          [ 1.0859e+00,  6.0547e-01,  5.4688e-01,  ...,  9.2969e-01,\n",
       "            3.3008e-01,  2.0508e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.0303e-01, -1.4844e-01,  4.2188e-01,  ..., -4.4922e-02,\n",
       "           -3.2422e-01, -2.8320e-01],\n",
       "          [-4.5654e-02, -1.9434e-01,  3.9844e-01,  ..., -5.4688e-02,\n",
       "           -4.5508e-01, -7.9102e-02],\n",
       "          [-2.2656e+00, -3.3906e+00, -3.8086e-01,  ..., -1.1719e+00,\n",
       "            1.3047e+00,  2.9688e+00],\n",
       "          ...,\n",
       "          [-1.9609e+00,  1.3477e-01, -1.8188e-02,  ...,  1.4062e+00,\n",
       "           -4.6484e-01,  1.0547e+00],\n",
       "          [-2.0625e+00,  2.7539e-01, -1.7969e+00,  ...,  2.2656e+00,\n",
       "           -1.1621e-01,  1.7266e+00],\n",
       "          [-3.7891e-01,  3.5156e-01, -1.4297e+00,  ...,  2.3145e-01,\n",
       "           -4.6484e-01, -2.2949e-01]],\n",
       "\n",
       "         [[-4.5117e-01, -2.3594e+00, -1.7344e+00,  ...,  3.6094e+00,\n",
       "           -1.5938e+00,  2.1562e+00],\n",
       "          [ 3.9219e+00, -2.4531e+00, -8.8672e-01,  ..., -1.3359e+00,\n",
       "           -1.1094e+00, -8.8672e-01],\n",
       "          [ 6.5430e-02, -5.7812e-01,  1.0859e+00,  ...,  1.9922e+00,\n",
       "           -1.8359e+00,  3.2031e-01],\n",
       "          ...,\n",
       "          [ 9.0820e-02,  7.1289e-02, -1.2969e+00,  ..., -2.3438e-01,\n",
       "            1.4648e-01,  5.6641e-01],\n",
       "          [ 4.0039e-01,  2.7539e-01, -5.3906e-01,  ...,  1.1169e-02,\n",
       "            3.4180e-02,  2.9297e-01],\n",
       "          [ 4.5898e-01,  5.2344e-01,  9.1016e-01,  ..., -1.5918e-01,\n",
       "            1.6094e+00,  3.6133e-01]],\n",
       "\n",
       "         [[-2.9663e-02, -2.2559e-01, -1.3281e-01,  ..., -2.6855e-02,\n",
       "           -4.4434e-02, -3.6133e-02],\n",
       "          [ 1.2695e-01, -1.0645e-01,  7.5684e-02,  ...,  5.0781e-01,\n",
       "            6.4453e-01, -6.1523e-02],\n",
       "          [ 2.0996e-02,  7.6660e-02, -4.1504e-02,  ..., -1.9434e-01,\n",
       "            1.6602e-02, -1.4941e-01],\n",
       "          ...,\n",
       "          [ 3.2969e+00,  1.9062e+00,  2.0938e+00,  ...,  2.6250e+00,\n",
       "            6.7578e-01,  2.6953e-01],\n",
       "          [-1.1182e-01, -3.7305e-01,  1.6602e-01,  ...,  3.5547e-01,\n",
       "           -5.9814e-02, -6.8750e-01],\n",
       "          [-7.2266e-02,  8.9453e-01, -6.5234e-01,  ..., -9.5703e-01,\n",
       "            1.1621e-01, -7.5684e-02]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-1.3184e-02, -1.8311e-02, -1.0681e-02,  ..., -5.8289e-03,\n",
       "            7.7820e-04,  5.3711e-03],\n",
       "          [-1.0452e-03, -2.3071e-02,  1.6968e-02,  ..., -6.8359e-02,\n",
       "           -1.2329e-02, -1.0645e-01],\n",
       "          [ 5.2344e-01,  2.6953e-01, -4.8828e-01,  ...,  5.2344e-01,\n",
       "           -1.7383e-01,  5.0781e-02],\n",
       "          ...,\n",
       "          [ 4.2812e+00, -1.1250e+00,  7.4219e-01,  ...,  2.4902e-01,\n",
       "            3.4531e+00,  2.1250e+00],\n",
       "          [ 1.3828e+00, -9.5703e-01,  1.0781e+00,  ...,  1.4453e+00,\n",
       "            7.3438e-01,  2.9844e+00],\n",
       "          [-1.1063e-03, -2.5269e-02, -1.0059e-01,  ..., -5.7031e-01,\n",
       "            4.7656e-01,  6.4087e-03]],\n",
       "\n",
       "         [[-6.1768e-02,  2.6123e-02, -8.7280e-03,  ..., -1.2634e-02,\n",
       "           -3.1128e-02,  9.7046e-03],\n",
       "          [ 5.1875e+00, -2.9375e+00,  3.3984e-01,  ...,  1.2422e+00,\n",
       "            6.7578e-01, -3.6562e+00],\n",
       "          [-1.2500e+00,  5.1953e-01, -1.6211e-01,  ..., -2.3047e-01,\n",
       "           -5.9375e-01,  2.5586e-01],\n",
       "          ...,\n",
       "          [-1.3906e+00,  1.6699e-01,  1.2031e+00,  ..., -9.3994e-03,\n",
       "            6.7969e-01,  7.5781e-01],\n",
       "          [ 1.3438e+00, -1.3750e+00,  1.2656e+00,  ..., -8.4375e-01,\n",
       "           -6.0156e-01,  3.4180e-01],\n",
       "          [ 8.6328e-01, -1.1172e+00,  2.3145e-01,  ..., -1.5781e+00,\n",
       "           -1.0625e+00, -2.1680e-01]],\n",
       "\n",
       "         [[-4.5312e-01, -9.4238e-02,  4.6289e-01,  ..., -6.6797e-01,\n",
       "           -3.0469e-01,  7.7209e-03],\n",
       "          [ 2.1387e-01, -1.1621e-01,  3.7305e-01,  ...,  1.4941e-01,\n",
       "           -9.7656e-01, -1.2354e-01],\n",
       "          [ 3.4424e-02, -2.0508e-02,  1.8262e-01,  ..., -7.5195e-02,\n",
       "           -3.5742e-01, -1.6846e-02],\n",
       "          ...,\n",
       "          [ 1.8652e-01,  2.1875e-01,  9.1797e-01,  ..., -2.1875e-01,\n",
       "            5.3125e-01, -4.8828e-01],\n",
       "          [-2.9492e-01,  2.0996e-01, -1.0625e+00,  ...,  8.9062e-01,\n",
       "           -1.4453e-01,  3.3008e-01],\n",
       "          [ 8.2031e-02, -3.5547e-01, -6.9141e-01,  ...,  8.0859e-01,\n",
       "           -1.3245e-02, -3.1641e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.3428e-02, -3.6865e-02, -1.9531e-02,  ...,  2.0264e-02,\n",
       "           -1.7578e-02,  5.0049e-03],\n",
       "          [ 1.3125e+00,  3.1641e-01,  4.7070e-01,  ...,  1.1328e+00,\n",
       "           -1.0859e+00, -5.4199e-02],\n",
       "          [ 1.2344e+00,  1.2812e+00,  8.2031e-01,  ...,  8.3594e-01,\n",
       "           -7.8906e-01, -1.4746e-01],\n",
       "          ...,\n",
       "          [-1.8828e+00, -1.6719e+00, -1.2734e+00,  ...,  8.8281e-01,\n",
       "           -5.7422e-01,  2.7539e-01],\n",
       "          [-5.7031e-01,  4.5508e-01,  1.7969e-01,  ...,  3.9648e-01,\n",
       "            1.2891e-01,  3.6133e-01],\n",
       "          [-5.1172e-01,  1.0547e+00, -5.1025e-02,  ...,  1.1841e-02,\n",
       "            5.5859e-01,  1.3184e-02]],\n",
       "\n",
       "         [[ 2.7148e-01, -2.1387e-01,  2.0020e-01,  ..., -2.4609e-01,\n",
       "           -4.6387e-02,  2.9492e-01],\n",
       "          [ 4.2773e-01, -2.5195e-01,  3.6328e-01,  ..., -4.8828e-01,\n",
       "           -6.1768e-02,  4.3164e-01],\n",
       "          [-1.0596e-01,  4.9609e-01,  1.9141e+00,  ...,  1.4062e-01,\n",
       "           -1.7188e+00, -1.1484e+00],\n",
       "          ...,\n",
       "          [-4.7656e-01, -4.8633e-01,  1.5078e+00,  ...,  3.8281e-01,\n",
       "            3.1445e-01, -5.7422e-01],\n",
       "          [ 1.1016e+00, -1.0254e-01, -1.4832e-02,  ...,  1.0938e+00,\n",
       "           -1.3672e+00, -2.1250e+00],\n",
       "          [ 6.0547e-01,  2.9297e-01, -7.2266e-02,  ...,  6.2109e-01,\n",
       "           -6.4844e-01, -1.4531e+00]],\n",
       "\n",
       "         [[ 4.1406e-01,  9.5703e-02, -1.0234e+00,  ...,  4.9609e-01,\n",
       "           -1.5312e+00, -1.8359e+00],\n",
       "          [ 7.6953e-01, -9.8877e-03, -1.2891e+00,  ...,  8.3594e-01,\n",
       "           -2.4219e-01,  4.9609e-01],\n",
       "          [ 8.2422e-01,  5.5469e-01,  3.4180e-01,  ..., -1.8457e-01,\n",
       "            3.0762e-02,  9.9609e-01],\n",
       "          ...,\n",
       "          [-6.0547e-01, -3.6523e-01,  1.3750e+00,  ..., -8.0859e-01,\n",
       "           -1.8047e+00,  3.0312e+00],\n",
       "          [ 8.0078e-02, -8.5938e-02, -1.1670e-01,  ..., -5.0049e-02,\n",
       "            2.2168e-01, -1.1523e-01],\n",
       "          [-3.2959e-02,  3.2227e-01,  3.4766e-01,  ...,  5.5859e-01,\n",
       "           -2.1387e-01,  2.3730e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 4.0625e-01, -4.8438e-01, -6.5430e-02,  ...,  5.2344e-01,\n",
       "           -3.4375e-01,  1.2500e-01],\n",
       "          [-4.2578e-01,  4.6680e-01, -7.0801e-02,  ..., -1.9043e-01,\n",
       "            5.0049e-02, -2.8516e-01],\n",
       "          [-1.3906e+00, -6.9141e-01, -6.8359e-01,  ..., -2.7930e-01,\n",
       "            1.7188e+00,  1.1641e+00],\n",
       "          ...,\n",
       "          [ 2.0781e+00, -1.5703e+00,  2.3281e+00,  ..., -2.5469e+00,\n",
       "            1.4375e+00, -7.1094e-01],\n",
       "          [ 9.2773e-02, -2.5977e-01,  4.0039e-01,  ..., -1.6992e-01,\n",
       "            2.9688e-01, -1.2512e-03],\n",
       "          [ 6.3672e-01, -1.1641e+00,  1.3281e+00,  ..., -1.3906e+00,\n",
       "            1.6328e+00, -9.0820e-02]],\n",
       "\n",
       "         [[ 3.6719e-01, -7.0703e-01,  1.0303e-01,  ...,  2.3438e-01,\n",
       "            7.6172e-02, -1.1816e-01],\n",
       "          [ 1.0781e+00, -8.9844e-01, -1.9336e-01,  ..., -1.2969e+00,\n",
       "            4.3945e-01, -1.1016e+00],\n",
       "          [-7.2656e-01, -1.7344e+00, -8.6719e-01,  ...,  2.6562e-01,\n",
       "            2.9492e-01, -6.3672e-01],\n",
       "          ...,\n",
       "          [-2.6562e-01,  1.6328e+00,  3.8477e-01,  ..., -3.1836e-01,\n",
       "           -5.1562e-01, -6.7578e-01],\n",
       "          [-3.1982e-02,  8.1055e-02,  7.2327e-03,  ...,  3.3936e-02,\n",
       "            2.4707e-01,  2.6562e-01],\n",
       "          [ 8.6328e-01, -4.9609e-01, -3.1719e+00,  ..., -3.3438e+00,\n",
       "           -1.1875e+00, -4.2812e+00]],\n",
       "\n",
       "         [[ 2.8906e+00,  1.8906e+00,  2.0625e+00,  ...,  2.8281e+00,\n",
       "            8.2812e-01,  2.3906e+00],\n",
       "          [ 1.3984e+00,  2.6367e-01,  9.0234e-01,  ...,  1.1172e+00,\n",
       "           -1.3672e+00, -4.0430e-01],\n",
       "          [ 1.1016e+00,  7.0801e-02,  7.4707e-02,  ..., -3.1738e-02,\n",
       "           -2.9883e-01,  3.0078e-01],\n",
       "          ...,\n",
       "          [-2.8281e+00, -1.3828e+00, -2.2031e+00,  ...,  1.1875e+00,\n",
       "            1.0469e+00,  9.0625e-01],\n",
       "          [ 1.2422e+00,  3.4961e-01,  6.9531e-01,  ..., -7.8906e-01,\n",
       "           -2.6367e-01, -7.3438e-01],\n",
       "          [ 1.7891e+00, -3.0078e-01,  8.4766e-01,  ...,  1.1016e+00,\n",
       "            1.2734e+00,  4.3359e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.0000e+00,  6.9531e-01, -1.1406e+00,  ...,  6.1719e-01,\n",
       "            6.4453e-02,  7.7734e-01],\n",
       "          [ 1.5547e+00,  1.2500e-01, -2.0312e-01,  ...,  2.3682e-02,\n",
       "            3.5742e-01,  1.5156e+00],\n",
       "          [ 7.1094e-01,  1.4688e+00,  5.4688e-01,  ..., -1.1953e+00,\n",
       "           -1.8438e+00,  1.2422e+00],\n",
       "          ...,\n",
       "          [ 8.5156e-01,  4.5312e-01,  4.0430e-01,  ...,  5.5859e-01,\n",
       "            9.4922e-01, -2.8320e-01],\n",
       "          [ 3.1094e+00,  1.4526e-02,  1.7188e+00,  ...,  4.7852e-01,\n",
       "            2.8594e+00,  1.0391e+00],\n",
       "          [-4.4727e-01,  4.3945e-01,  1.3672e+00,  ..., -1.2422e+00,\n",
       "           -1.7344e+00, -1.9062e+00]],\n",
       "\n",
       "         [[ 7.4707e-02, -9.9487e-03, -4.8340e-02,  ...,  3.1445e-01,\n",
       "            1.0889e-01,  1.2012e-01],\n",
       "          [-9.1797e-02,  2.7222e-02, -1.8652e-01,  ...,  3.1250e-01,\n",
       "            1.8066e-01,  3.2812e-01],\n",
       "          [-6.7969e-01,  1.5703e+00,  2.0215e-01,  ...,  4.2236e-02,\n",
       "           -9.0234e-01, -4.8633e-01],\n",
       "          ...,\n",
       "          [-1.9922e+00, -4.1992e-01, -3.2422e-01,  ...,  4.0234e-01,\n",
       "           -7.3047e-01, -1.7109e+00],\n",
       "          [-1.0547e+00, -6.5918e-02, -9.8828e-01,  ...,  4.1016e-02,\n",
       "            3.8867e-01,  1.7578e-01],\n",
       "          [-4.2500e+00,  4.7302e-03,  4.2188e+00,  ..., -5.5859e-01,\n",
       "           -1.4609e+00,  2.0996e-01]],\n",
       "\n",
       "         [[ 2.2461e-02, -8.9355e-02, -3.4180e-02,  ...,  4.9072e-02,\n",
       "           -2.6367e-02, -4.3701e-02],\n",
       "          [-2.6758e-01,  8.8281e-01,  4.8047e-01,  ..., -2.9297e-01,\n",
       "            3.2617e-01,  1.0498e-01],\n",
       "          [-1.6113e-01,  2.3633e-01, -3.3594e-01,  ...,  5.8594e-01,\n",
       "           -7.5391e-01, -6.8750e-01],\n",
       "          ...,\n",
       "          [ 3.3438e+00, -3.0938e+00,  2.0938e+00,  ..., -3.0312e+00,\n",
       "           -1.9297e+00, -3.2812e+00],\n",
       "          [-1.7578e+00,  1.6875e+00, -1.8906e+00,  ...,  5.4062e+00,\n",
       "            9.7266e-01,  4.1562e+00],\n",
       "          [-4.1016e-01,  2.1094e+00, -4.3359e-01,  ..., -1.7656e+00,\n",
       "            3.1445e-01,  4.0527e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 1.7266e+00, -7.2266e-01,  2.8320e-01,  ...,  9.7266e-01,\n",
       "            6.0547e-01, -6.4844e-01],\n",
       "          [-1.6797e+00, -5.3906e-01, -3.1250e-02,  ...,  1.3047e+00,\n",
       "           -3.9062e-01, -3.8125e+00],\n",
       "          [ 4.7461e-01, -1.2812e+00,  1.1797e+00,  ..., -7.1875e-01,\n",
       "           -3.3281e+00,  9.1797e-01],\n",
       "          ...,\n",
       "          [-1.0059e-01,  6.0547e-02,  1.6504e-01,  ..., -3.1641e-01,\n",
       "            2.9297e-01,  1.6699e-01],\n",
       "          [-2.0142e-03,  6.7188e-01, -8.2812e-01,  ..., -7.2754e-02,\n",
       "            7.7148e-02,  1.4062e-01],\n",
       "          [-1.3379e-01, -2.0156e+00,  5.6641e-01,  ...,  8.1543e-02,\n",
       "            3.0859e-01,  1.1250e+00]],\n",
       "\n",
       "         [[ 1.9336e-01,  4.5312e-01,  1.1094e+00,  ..., -4.6875e-02,\n",
       "           -8.2812e-01, -4.6680e-01],\n",
       "          [-1.4219e+00,  4.4062e+00, -7.3047e-01,  ..., -4.8096e-02,\n",
       "            7.1094e-01,  2.0312e+00],\n",
       "          [-5.2344e-01,  3.1094e+00, -2.3633e-01,  ..., -4.7266e-01,\n",
       "            2.3750e+00,  6.7969e-01],\n",
       "          ...,\n",
       "          [ 1.1875e+00, -1.8652e-01, -9.6875e-01,  ..., -2.0000e+00,\n",
       "            4.1748e-02,  2.0215e-01],\n",
       "          [ 4.2773e-01,  7.0312e-01, -1.2656e+00,  ...,  1.4609e+00,\n",
       "            3.7344e+00,  1.2695e-01],\n",
       "          [ 2.3560e-02, -2.4805e-01,  6.4062e-01,  ..., -6.9141e-01,\n",
       "           -2.1875e+00, -4.7461e-01]],\n",
       "\n",
       "         [[-9.3262e-02,  1.7776e-03, -1.4160e-01,  ..., -8.0566e-02,\n",
       "            9.1797e-02, -5.0293e-02],\n",
       "          [ 4.7119e-02, -1.1182e-01,  5.9375e-01,  ...,  3.5156e-01,\n",
       "           -6.0547e-01,  2.8906e-01],\n",
       "          [-1.8047e+00,  9.6094e-01, -1.2061e-01,  ...,  8.5547e-01,\n",
       "           -3.8086e-01, -7.3730e-02],\n",
       "          ...,\n",
       "          [-8.3984e-02,  2.0938e+00, -1.2891e+00,  ..., -4.7266e-01,\n",
       "            5.5469e-01,  5.1758e-02],\n",
       "          [-1.3359e+00, -1.7578e+00, -2.0156e+00,  ..., -9.6094e-01,\n",
       "           -5.1562e-01, -1.7656e+00],\n",
       "          [ 1.8359e-01,  1.5039e-01,  3.1055e-01,  ...,  1.3379e-01,\n",
       "           -6.0547e-02,  2.6953e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.5000e-01, -4.8242e-01, -2.5781e-01,  ...,  3.2812e-01,\n",
       "           -5.9766e-01, -5.7602e-04],\n",
       "          [ 4.0430e-01, -1.5234e-01, -8.7891e-01,  ..., -4.2578e-01,\n",
       "           -8.2031e-01, -7.2266e-01],\n",
       "          [ 9.9219e-01, -1.2891e+00,  1.0625e+00,  ...,  9.0234e-01,\n",
       "            3.2422e-01,  1.3984e+00],\n",
       "          ...,\n",
       "          [ 2.2969e+00,  6.1250e+00, -1.7188e-01,  ..., -4.8125e+00,\n",
       "           -1.3984e+00,  1.8516e+00],\n",
       "          [-2.0781e+00, -6.4062e-01,  1.9434e-01,  ...,  6.9141e-01,\n",
       "            8.7500e-01,  1.2734e+00],\n",
       "          [ 2.8320e-01, -1.5469e+00,  1.0703e+00,  ...,  1.8594e+00,\n",
       "           -1.6250e+00,  5.1562e-01]],\n",
       "\n",
       "         [[ 2.5586e-01,  2.4219e-01, -3.3203e-01,  ...,  2.3438e-01,\n",
       "           -7.2656e-01, -1.9043e-01],\n",
       "          [-6.2500e-01, -1.4160e-01,  3.9648e-01,  ..., -1.5503e-02,\n",
       "            1.3828e+00,  1.1406e+00],\n",
       "          [ 1.4688e+00, -8.6719e-01,  3.9258e-01,  ..., -1.1328e+00,\n",
       "           -1.5078e+00, -3.7031e+00],\n",
       "          ...,\n",
       "          [-4.8242e-01, -2.0625e+00, -1.8652e-01,  ...,  5.5469e-01,\n",
       "            6.8359e-01,  1.3123e-02],\n",
       "          [-8.1055e-02,  4.1211e-01, -1.7109e+00,  ...,  1.1641e+00,\n",
       "           -1.0781e+00, -1.1953e+00],\n",
       "          [ 2.4805e-01,  1.0693e-01,  2.3926e-01,  ...,  1.6992e-01,\n",
       "           -5.9082e-02, -5.0537e-02]],\n",
       "\n",
       "         [[-4.5000e+00,  9.4922e-01, -1.2969e+00,  ...,  9.8145e-02,\n",
       "           -2.2852e-01, -8.6719e-01],\n",
       "          [-7.5195e-02,  8.6328e-01,  2.4062e+00,  ..., -2.4170e-02,\n",
       "           -1.0312e+00,  9.2969e-01],\n",
       "          [-2.4023e-01, -7.4219e-01,  5.5078e-01,  ...,  2.9102e-01,\n",
       "            2.4609e-01, -1.3770e-01],\n",
       "          ...,\n",
       "          [-1.3984e+00,  9.8145e-02,  7.6953e-01,  ..., -3.8281e-01,\n",
       "            6.6406e-01,  5.1562e-01],\n",
       "          [-1.5156e+00, -5.5078e-01,  1.6172e+00,  ...,  1.7090e-01,\n",
       "            1.2656e+00,  1.0312e+00],\n",
       "          [-2.5156e+00, -2.5156e+00, -2.6953e-01,  ...,  9.9609e-02,\n",
       "           -5.0312e+00,  7.0703e-01]]]], device='cuda:0', dtype=torch.bfloat16,\n",
       "       grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "045da727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0625, device='cuda:0', dtype=torch.bfloat16, grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(out - out_).abs().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a538bd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "out.mean().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64cb771a",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_.mean().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e505da0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.7253e-09, device='cuda:0', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(query_states.grad - query_states_.grad).abs().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76eda87a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.4506e-09, device='cuda:0', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(key_states.grad - key_states_.grad).abs().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbc42c66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.7253e-09, device='cuda:0', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(value_states.grad - value_states_.grad).abs().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c78a9e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.2187e-05, device='cuda:0', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(A.grad - A_.grad).abs().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950c4b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/gmongaras/miniconda3/lib/python3.10/site-packages/torch/autograd/gradcheck.py:922: UserWarning: Input #0 requires gradient and is not a double precision floating point or complex. This check will likely fail if all the inputs are not of double precision floating point or complex. \n",
      "  warnings.warn(\n",
      "/users/gmongaras/miniconda3/lib/python3.10/site-packages/torch/autograd/gradcheck.py:922: UserWarning: Input #1 requires gradient and is not a double precision floating point or complex. This check will likely fail if all the inputs are not of double precision floating point or complex. \n",
      "  warnings.warn(\n",
      "/users/gmongaras/miniconda3/lib/python3.10/site-packages/torch/autograd/gradcheck.py:922: UserWarning: Input #3 requires gradient and is not a double precision floating point or complex. This check will likely fail if all the inputs are not of double precision floating point or complex. \n",
      "  warnings.warn(\n",
      "/users/gmongaras/miniconda3/lib/python3.10/site-packages/torch/autograd/gradcheck.py:922: UserWarning: Input #4 requires gradient and is not a double precision floating point or complex. This check will likely fail if all the inputs are not of double precision floating point or complex. \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 91.38 MiB is free. Process 593366 has 988.00 MiB memory in use. Including non-PyTorch memory, this process has 78.18 GiB memory in use. Of the allocated memory 76.30 GiB is allocated by PyTorch, and 316.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m check \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmamba_chunk_scan_combined\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue_states__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue_states__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_states__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_states__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_states___\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/autograd/gradcheck.py:2055\u001b[0m, in \u001b[0;36mgradcheck\u001b[0;34m(func, inputs, eps, atol, rtol, raise_exception, nondet_tol, check_undefined_grad, check_grad_dtypes, check_batched_grad, check_batched_forward_grad, check_forward_ad, check_backward_ad, fast_mode, masked)\u001b[0m\n\u001b[1;32m   2053\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   2054\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2055\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_gradcheck_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/autograd/gradcheck.py:2084\u001b[0m, in \u001b[0;36m_gradcheck_helper\u001b[0;34m(func, inputs, eps, atol, rtol, nondet_tol, check_undefined_grad, check_grad_dtypes, check_batched_grad, check_batched_forward_grad, check_forward_ad, check_backward_ad, fast_mode, masked)\u001b[0m\n\u001b[1;32m   2079\u001b[0m _check_outputs(outputs)\n\u001b[1;32m   2081\u001b[0m gradcheck_fn \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(\n\u001b[1;32m   2082\u001b[0m     _fast_gradcheck \u001b[38;5;28;01mif\u001b[39;00m fast_mode \u001b[38;5;28;01melse\u001b[39;00m _slow_gradcheck, masked\u001b[38;5;241m=\u001b[39mmasked\n\u001b[1;32m   2083\u001b[0m )\n\u001b[0;32m-> 2084\u001b[0m \u001b[43m_gradcheck_real_imag\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2085\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgradcheck_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2086\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2087\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc_out\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2088\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtupled_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2089\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2090\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2091\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2092\u001b[0m \u001b[43m    \u001b[49m\u001b[43matol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2093\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_grad_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2094\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_forward_ad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_forward_ad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2095\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_backward_ad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_backward_ad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2096\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnondet_tol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnondet_tol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_undefined_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_undefined_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2098\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_batched_forward_grad:\n\u001b[1;32m   2101\u001b[0m     _test_batched_grad_forward_ad(func, tupled_inputs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/autograd/gradcheck.py:1494\u001b[0m, in \u001b[0;36m_gradcheck_real_imag\u001b[0;34m(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps, rtol, atol, check_grad_dtypes, check_forward_ad, check_backward_ad, nondet_tol, check_undefined_grad)\u001b[0m\n\u001b[1;32m   1481\u001b[0m         gradcheck_fn(\n\u001b[1;32m   1482\u001b[0m             real_fn,\n\u001b[1;32m   1483\u001b[0m             real_func_out,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1491\u001b[0m             complex_indices\u001b[38;5;241m=\u001b[39mcomplex_out_indices,\n\u001b[1;32m   1492\u001b[0m         )\n\u001b[1;32m   1493\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1494\u001b[0m         \u001b[43mgradcheck_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1495\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1496\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc_out\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1497\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtupled_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1498\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1499\u001b[0m \u001b[43m            \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1500\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m            \u001b[49m\u001b[43matol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcheck_grad_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnondet_tol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_forward_ad:\n\u001b[1;32m   1507\u001b[0m     complex_inp_indices \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   1508\u001b[0m         i\n\u001b[1;32m   1509\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i, inp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tupled_inputs)\n\u001b[1;32m   1510\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m is_tensor_like(inp) \u001b[38;5;129;01mand\u001b[39;00m inp\u001b[38;5;241m.\u001b[39mis_complex()\n\u001b[1;32m   1511\u001b[0m     ]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/autograd/gradcheck.py:1601\u001b[0m, in \u001b[0;36m_slow_gradcheck\u001b[0;34m(func, func_out, tupled_inputs, outputs, eps, rtol, atol, check_grad_dtypes, nondet_tol, use_forward_ad, complex_indices, test_imag, masked)\u001b[0m\n\u001b[1;32m   1595\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _check_no_differentiable_outputs(\n\u001b[1;32m   1596\u001b[0m         func, tupled_inputs, func_out, eps\u001b[38;5;241m=\u001b[39meps, is_forward_ad\u001b[38;5;241m=\u001b[39muse_forward_ad\n\u001b[1;32m   1597\u001b[0m     )\n\u001b[1;32m   1598\u001b[0m tupled_inputs_numerical \u001b[38;5;241m=\u001b[39m tupled_inputs \u001b[38;5;28;01mif\u001b[39;00m masked \u001b[38;5;28;01melse\u001b[39;00m _densify(tupled_inputs)\n\u001b[1;32m   1600\u001b[0m numerical \u001b[38;5;241m=\u001b[39m _transpose(\n\u001b[0;32m-> 1601\u001b[0m     \u001b[43m_get_numerical_jacobian\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtupled_inputs_numerical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1604\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc_out\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1605\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1606\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_forward_ad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_forward_ad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1607\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1608\u001b[0m )\n\u001b[1;32m   1609\u001b[0m \u001b[38;5;66;03m# Note: [numerical vs analytical output length]\u001b[39;00m\n\u001b[1;32m   1610\u001b[0m \u001b[38;5;66;03m# The numerical path returns jacobian quantity for all outputs, even if requires_grad of that\u001b[39;00m\n\u001b[1;32m   1611\u001b[0m \u001b[38;5;66;03m# output is False. This behavior is necessary for _check_no_differentiable_outputs to work.\u001b[39;00m\n\u001b[1;32m   1612\u001b[0m numerical \u001b[38;5;241m=\u001b[39m [nj \u001b[38;5;28;01mfor\u001b[39;00m o, nj \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(func_out, numerical) \u001b[38;5;28;01mif\u001b[39;00m o\u001b[38;5;241m.\u001b[39mrequires_grad]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/autograd/gradcheck.py:299\u001b[0m, in \u001b[0;36m_get_numerical_jacobian\u001b[0;34m(fn, inputs, outputs, target, eps, is_forward_ad)\u001b[0m\n\u001b[1;32m    294\u001b[0m inp_indices \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    295\u001b[0m     i \u001b[38;5;28;01mfor\u001b[39;00m i, a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(target) \u001b[38;5;28;01mif\u001b[39;00m is_tensor_like(a) \u001b[38;5;129;01mand\u001b[39;00m a\u001b[38;5;241m.\u001b[39mrequires_grad\n\u001b[1;32m    296\u001b[0m ]\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (inp, inp_idx) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(_iter_tensors(target, \u001b[38;5;28;01mTrue\u001b[39;00m), inp_indices)):\n\u001b[1;32m    298\u001b[0m     jacobians \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 299\u001b[0m         \u001b[43mget_numerical_jacobian_wrt_specific_input\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m            \u001b[49m\u001b[43minp_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m            \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m            \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m            \u001b[49m\u001b[43mis_forward_ad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_forward_ad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    308\u001b[0m     ]\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m jacobians\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/autograd/gradcheck.py:488\u001b[0m, in \u001b[0;36mget_numerical_jacobian_wrt_specific_input\u001b[0;34m(fn, input_idx, inputs, outputs, eps, input, is_forward_ad)\u001b[0m\n\u001b[1;32m    482\u001b[0m     nbhd_checks_fn \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(\n\u001b[1;32m    483\u001b[0m         _check_outputs_same_dtype_and_shape, idx\u001b[38;5;241m=\u001b[39midx, eps\u001b[38;5;241m=\u001b[39meps\n\u001b[1;32m    484\u001b[0m     )\n\u001b[1;32m    485\u001b[0m     jvp_fn \u001b[38;5;241m=\u001b[39m _get_numerical_jvp_fn(\n\u001b[1;32m    486\u001b[0m         wrapped_fn, input_to_perturb, eps, nbhd_checks_fn\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m     jacobian_cols[d_idx] \u001b[38;5;241m=\u001b[39m \u001b[43m_compute_numerical_jvps_wrt_specific_input\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjvp_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_forward_ad\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _combine_jacobian_cols(jacobian_cols, outputs, \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mnumel())\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/autograd/gradcheck.py:396\u001b[0m, in \u001b[0;36m_compute_numerical_jvps_wrt_specific_input\u001b[0;34m(jvp_fn, delta, input_is_complex, is_forward_ad)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_compute_numerical_jvps_wrt_specific_input\u001b[39m(\n\u001b[1;32m    388\u001b[0m     jvp_fn, delta, input_is_complex, is_forward_ad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    389\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;66;03m# s = fn(z) where z = x for real valued input\u001b[39;00m\n\u001b[1;32m    394\u001b[0m     \u001b[38;5;66;03m# and z = x + yj for complex valued input\u001b[39;00m\n\u001b[1;32m    395\u001b[0m     jvps: List[torch\u001b[38;5;241m.\u001b[39mTensor] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 396\u001b[0m     ds_dx_tup \u001b[38;5;241m=\u001b[39m \u001b[43mjvp_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelta\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdelta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdelta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    398\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m input_is_complex:  \u001b[38;5;66;03m# C -> R\u001b[39;00m\n\u001b[1;32m    399\u001b[0m         ds_dy_tup \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    400\u001b[0m             jvp_fn(delta[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1\u001b[39mj) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(delta, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m jvp_fn(delta \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1\u001b[39mj)\n\u001b[1;32m    401\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/autograd/gradcheck.py:635\u001b[0m, in \u001b[0;36m_get_numerical_jvp_fn.<locals>.jvp_fn\u001b[0;34m(delta)\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mjvp_fn\u001b[39m(delta):\n\u001b[0;32m--> 635\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compute_numerical_gradient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwrapped_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_to_perturb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbhd_checks_fn\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/autograd/gradcheck.py:374\u001b[0m, in \u001b[0;36m_compute_numerical_gradient\u001b[0;34m(fn, entry, v, norm_v, nbhd_checks_fn)\u001b[0m\n\u001b[1;32m    372\u001b[0m orig \u001b[38;5;241m=\u001b[39m entry\u001b[38;5;241m.\u001b[39mclone()\n\u001b[1;32m    373\u001b[0m entry\u001b[38;5;241m.\u001b[39mcopy_(orig \u001b[38;5;241m-\u001b[39m v)\n\u001b[0;32m--> 374\u001b[0m outa \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    375\u001b[0m entry\u001b[38;5;241m.\u001b[39mcopy_(orig \u001b[38;5;241m+\u001b[39m v)\n\u001b[1;32m    376\u001b[0m outb \u001b[38;5;241m=\u001b[39m fn()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/autograd/gradcheck.py:627\u001b[0m, in \u001b[0;36m_with_prepare_inputs.<locals>.wrapped_fn\u001b[0;34m()\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_fn\u001b[39m():\n\u001b[1;32m    621\u001b[0m     inp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[1;32m    622\u001b[0m         _prepare_input(a, input_to_perturb \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m input_idx \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, fast_mode)\n\u001b[1;32m    623\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m is_tensor_like(a)\n\u001b[1;32m    624\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m a\n\u001b[1;32m    625\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i, a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(_as_tuple(inputs))\n\u001b[1;32m    626\u001b[0m     )\n\u001b[0;32m--> 627\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(a\u001b[38;5;241m.\u001b[39mclone() \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m _as_tuple(\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m))\n",
      "File \u001b[0;32m/work/projects/eclarson/sm_taylor/gmongaras_sm_taylor/Gated-Attention-V2/mamba_test/Mamba_Custom.py:665\u001b[0m, in \u001b[0;36mmamba_chunk_scan_combined\u001b[0;34m(x, dt, A, B, C, chunk_size, D, z, dt_bias, initial_states, seq_idx, cu_seqlens, dt_softplus, dt_limit, return_final_states, return_varlen_states)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmamba_chunk_scan_combined\u001b[39m(x, dt, A, B, C, chunk_size, D\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, z\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dt_bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, initial_states\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, seq_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, cu_seqlens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dt_softplus\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dt_limit\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m\"\u001b[39m)), return_final_states\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, return_varlen_states\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    647\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;124;03m    Argument:\u001b[39;00m\n\u001b[1;32m    649\u001b[0m \u001b[38;5;124;03m        x: (batch, seqlen, nheads, headdim)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    663\u001b[0m \u001b[38;5;124;03m        out: (batch, seqlen, nheads, headdim)\u001b[39;00m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 665\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMambaChunkScanCombinedFn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt_bias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcu_seqlens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt_softplus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt_limit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_final_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_varlen_states\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/autograd/function.py:575\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    573\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    574\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 575\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    579\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    580\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    582\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/main/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    583\u001b[0m     )\n",
      "File \u001b[0;32m/work/projects/eclarson/sm_taylor/gmongaras_sm_taylor/Gated-Attention-V2/mamba_test/Mamba_Custom.py:624\u001b[0m, in \u001b[0;36mMambaChunkScanCombinedFn.forward\u001b[0;34m(ctx, x, dt, A, B, C, chunk_size, D, z, dt_bias, initial_states, seq_idx, cu_seqlens, dt_softplus, dt_limit, return_final_states, return_varlen_states)\u001b[0m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m cu_seqlens \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcu_seqlens must be provided if return_varlen_states is True\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 624\u001b[0m out, out_x, dt_out, dA_cumsum, states, final_states, \u001b[38;5;241m*\u001b[39mrest \u001b[38;5;241m=\u001b[39m \u001b[43m_mamba_chunk_scan_combined_fwd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mD\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdt_bias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseq_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcu_seqlens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcu_seqlens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt_softplus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdt_softplus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdt_limit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    625\u001b[0m ctx\u001b[38;5;241m.\u001b[39msave_for_backward(out \u001b[38;5;28;01mif\u001b[39;00m z \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m out_x, x, dt, dA_cumsum, A, B, C, D, z, dt_bias, initial_states, seq_idx)\n\u001b[1;32m    626\u001b[0m ctx\u001b[38;5;241m.\u001b[39mdt_softplus \u001b[38;5;241m=\u001b[39m dt_softplus\n",
      "File \u001b[0;32m/work/projects/eclarson/sm_taylor/gmongaras_sm_taylor/Gated-Attention-V2/mamba_test/Mamba_Custom.py:365\u001b[0m, in \u001b[0;36m_mamba_chunk_scan_combined_fwd\u001b[0;34m(x, dt, A, B, C, chunk_size, D, z, dt_bias, initial_states, seq_idx, cu_seqlens, dt_softplus, dt_limit)\u001b[0m\n\u001b[1;32m    362\u001b[0m states, final_states \u001b[38;5;241m=\u001b[39m [rearrange(t, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m... (p n) -> ... p n\u001b[39m\u001b[38;5;124m\"\u001b[39m, n\u001b[38;5;241m=\u001b[39mdstate) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m [states, final_states]]\n\u001b[1;32m    363\u001b[0m \u001b[38;5;66;03m# states_tmp0 = rearrange(_state_passing_fwd(rearrange(states_tmp0, \"... p n -> ... (p n)\"), dA_cumsum_tmp0[:, :, :, -1], chunk_size=chunk_size), \"... (p n) -> ... p n\", n=dstate)\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;66;03m# states_tmp1 = rearrange(_state_passing_fwd(rearrange(states_tmp1, \"... p n -> ... (p n)\"), dA_cumsum_tmp1[:, :, :, -1], chunk_size=chunk_size), \"... (p n) -> ... p n\", n=dstate)\u001b[39;00m\n\u001b[0;32m--> 365\u001b[0m CB \u001b[38;5;241m=\u001b[39m \u001b[43m_bmm_chunk_fwd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseq_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    366\u001b[0m out, out_x \u001b[38;5;241m=\u001b[39m _chunk_scan_fwd(CB, x, dt, dA_cumsum, C, states, D\u001b[38;5;241m=\u001b[39mD, z\u001b[38;5;241m=\u001b[39mz, seq_idx\u001b[38;5;241m=\u001b[39mseq_idx)\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cu_seqlens \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/mamba_ssm/ops/triton/ssd_bmm.py:190\u001b[0m, in \u001b[0;36m_bmm_chunk_fwd\u001b[0;34m(a, b, chunk_size, seq_idx, causal, output_dtype)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m# Allocates output.\u001b[39;00m\n\u001b[1;32m    189\u001b[0m out_dtype \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;28;01mif\u001b[39;00m output_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m output_dtype\n\u001b[0;32m--> 190\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnchunks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhas_groups\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnchunks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mngroups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m dot_dtype \u001b[38;5;241m=\u001b[39m (tl\u001b[38;5;241m.\u001b[39mbfloat16 \u001b[38;5;28;01mif\u001b[39;00m a\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mbfloat16 \u001b[38;5;129;01mor\u001b[39;00m b\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mbfloat16 \u001b[38;5;28;01melse\u001b[39;00m\n\u001b[1;32m    193\u001b[0m              (tl\u001b[38;5;241m.\u001b[39mfloat16 \u001b[38;5;28;01mif\u001b[39;00m a\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat16 \u001b[38;5;129;01mor\u001b[39;00m b\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat16 \u001b[38;5;28;01melse\u001b[39;00m tl\u001b[38;5;241m.\u001b[39mfloat32))\n\u001b[1;32m    194\u001b[0m grid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m META: (triton\u001b[38;5;241m.\u001b[39mcdiv(chunk_size, META[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBLOCK_SIZE_M\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m*\u001b[39m triton\u001b[38;5;241m.\u001b[39mcdiv(chunk_size, META[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBLOCK_SIZE_N\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[1;32m    195\u001b[0m                 batch, nchunks \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_groups \u001b[38;5;28;01melse\u001b[39;00m nchunks \u001b[38;5;241m*\u001b[39m ngroups)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 91.38 MiB is free. Process 593366 has 988.00 MiB memory in use. Including non-PyTorch memory, this process has 78.18 GiB memory in use. Of the allocated memory 76.30 GiB is allocated by PyTorch, and 316.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9e18b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ccbe3c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.7253e-09, device='cuda:0', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(query_states.grad - query_states_.grad).abs().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7dc0030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.4506e-09, device='cuda:0', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(key_states.grad - key_states_.grad).abs().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20280d42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.7253e-09, device='cuda:0', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(value_states.grad - value_states_.grad).abs().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f13433c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.2187e-05, device='cuda:0', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(A.grad - A_.grad).abs().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63995e26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ff31ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
